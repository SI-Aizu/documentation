{"config":{"lang":["ja"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-\\.]+"},"docs":[{"location":"","text":"Home \u00b6 Issues | Pull Request | Dependabot | Actions | Packages | Releases \u7814\u7a76\u5ba4\u30e1\u30f3\u30d0\u30fc\u5411\u3051\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3002 \u74b0\u5883\u69cb\u7bc9 Useful Links Tutorials Git and GitHub Bing Image Search VoTT PyTorch TensorFlow TensorFlow Models \u95a2\u4fc2\u8005\u4ee5\u5916\u306e\u95b2\u89a7\u8005\u3078 \u00b6 \u3053\u306e\u30b5\u30a4\u30c8\u30fb\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u30b3\u30f3\u30c6\u30f3\u30c4\u306b\u3064\u3044\u3066\u3002 \u95b2\u89a7\u306f\u3054\u81ea\u7531\u306b\u3069\u3046\u305e\u3002 MIT License \u306e\u3082\u3068\u3067\u5229\u7528\u3057\u3066\u3044\u305f\u3060\u3051\u307e\u3059\u3002\u30b5\u30dd\u30fc\u30c8\u3084\u4fdd\u8a3c\u306f\u4e00\u5207\u3057\u307e\u305b\u3093\u3002 \u3053\u306e\u30b5\u30a4\u30c8\u306f\u30a2\u30af\u30bb\u30b9\u89e3\u6790\u30c4\u30fc\u30eb\u3092\u8a2d\u7f6e\u3057\u3066\u3044\u307e\u305b\u3093\u3002 \u30b5\u30a4\u30c8\u306e\u30ed\u30fc\u30ab\u30eb\u30d7\u30ec\u30d3\u30e5\u30fc \u00b6 \u5229\u7528\u3067\u304d\u308b\u62e1\u5f35\u8a18\u6cd5\u3084\u30b5\u30a4\u30c8\u8a2d\u5b9a\u65b9\u6cd5\u306b\u3064\u3044\u3066\u306f\u4ee5\u4e0b\u3092\u53c2\u7167\u3002 Material for MkDocs git clone https://github.com/SI-Aizu/documentation.git # OR git clone git@github.com:SI-Aizu/documentation.git # mkdocs serve docker-compose up http://localhost:8888 # \u7d42\u308f\u3063\u305f\u3089\u30b3\u30f3\u30c6\u30ca\u3092\u7247\u4ed8\u3051\u308b docker-compose down","title":"Home"},{"location":"#home","text":"Issues | Pull Request | Dependabot | Actions | Packages | Releases \u7814\u7a76\u5ba4\u30e1\u30f3\u30d0\u30fc\u5411\u3051\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3002 \u74b0\u5883\u69cb\u7bc9 Useful Links Tutorials Git and GitHub Bing Image Search VoTT PyTorch TensorFlow TensorFlow Models","title":"Home"},{"location":"#_1","text":"\u3053\u306e\u30b5\u30a4\u30c8\u30fb\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u30b3\u30f3\u30c6\u30f3\u30c4\u306b\u3064\u3044\u3066\u3002 \u95b2\u89a7\u306f\u3054\u81ea\u7531\u306b\u3069\u3046\u305e\u3002 MIT License \u306e\u3082\u3068\u3067\u5229\u7528\u3057\u3066\u3044\u305f\u3060\u3051\u307e\u3059\u3002\u30b5\u30dd\u30fc\u30c8\u3084\u4fdd\u8a3c\u306f\u4e00\u5207\u3057\u307e\u305b\u3093\u3002 \u3053\u306e\u30b5\u30a4\u30c8\u306f\u30a2\u30af\u30bb\u30b9\u89e3\u6790\u30c4\u30fc\u30eb\u3092\u8a2d\u7f6e\u3057\u3066\u3044\u307e\u305b\u3093\u3002","title":"\u95a2\u4fc2\u8005\u4ee5\u5916\u306e\u95b2\u89a7\u8005\u3078"},{"location":"#_2","text":"\u5229\u7528\u3067\u304d\u308b\u62e1\u5f35\u8a18\u6cd5\u3084\u30b5\u30a4\u30c8\u8a2d\u5b9a\u65b9\u6cd5\u306b\u3064\u3044\u3066\u306f\u4ee5\u4e0b\u3092\u53c2\u7167\u3002 Material for MkDocs git clone https://github.com/SI-Aizu/documentation.git # OR git clone git@github.com:SI-Aizu/documentation.git # mkdocs serve docker-compose up http://localhost:8888 # \u7d42\u308f\u3063\u305f\u3089\u30b3\u30f3\u30c6\u30ca\u3092\u7247\u4ed8\u3051\u308b docker-compose down","title":"\u30b5\u30a4\u30c8\u306e\u30ed\u30fc\u30ab\u30eb\u30d7\u30ec\u30d3\u30e5\u30fc"},{"location":"Useful-Links/","text":"Useful Links \u00b6 \u6559\u6750 \u00b6 yoyoyo-yo/Gasyori100knock: \u753b\u50cf\u51e6\u7406100\u672c\u30ce\u30c3\u30af - Image Processing \u5165\u9580 yoyoyo-yo/DeepLearningMugenKnock: \u6df1\u5c64\u5b66\u7fd2\u7121\u9650\u30ce\u30c3\u30af - Deep Learning \u5165\u9580 \u8a00\u8a9e\u51e6\u7406100\u672c\u30ce\u30c3\u30af - Natural Language Processing (NLP) \u5165\u9580 arXivTimes/arXivTimes - \u8ad6\u6587\u306e Abstract \u8981\u7d04\u3092\u96c6\u3081\u305f\u30ea\u30dd\u30b8\u30c8\u30ea Datasets \u00b6 Food-101 zalandoresearch/fashion-mnist - FMNIST \u8863\u670d\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8 DataSets - arXivTimes/arXivTimes - \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u4e00\u89a7 ObjectNet - ImageNet \u3088\u308a\u96e3\u6613\u5ea6\u306e\u9ad8\u3044\u30c6\u30b9\u30c8\u7528\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8 Logo \u30ed\u30b4 msn199959/Logo-2k-plus-Dataset: Logo-2k-plus-Dataset LLD - Large Logo Dataset WebLogo-2M Dataset QMUL-OpenLogo Flickr Logos dataset | IVA Computer Vision Datasets CNN \u53ef\u8996\u5316 cnn-explainer \u00b6 live demo: CNN Explainer repo: poloclub/cnn-explainer: Learning Convolutional Neural Networks with Interactive Visualization. GIGAZINE: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u624b\u6cd5\u300cCNN\u300d\u306e\u753b\u50cf\u8b58\u5225\u51e6\u7406\u304c\u30a2\u30cb\u30e1\u30fc\u30b7\u30e7\u30f3\u3067\u7406\u89e3\u3067\u304d\u308b\u300cCNN Explainer\u300d - GIGAZINE matplotlib \u00b6 matplotlib/cheatsheets: Official Matplotlib cheat sheets Object Detection Model List \u00b6 hoya012/deep_learning_object_detection: A paper list of object detection using deep learning.","title":"Useful Links"},{"location":"Useful-Links/#useful_links","text":"","title":"Useful Links"},{"location":"Useful-Links/#_1","text":"yoyoyo-yo/Gasyori100knock: \u753b\u50cf\u51e6\u7406100\u672c\u30ce\u30c3\u30af - Image Processing \u5165\u9580 yoyoyo-yo/DeepLearningMugenKnock: \u6df1\u5c64\u5b66\u7fd2\u7121\u9650\u30ce\u30c3\u30af - Deep Learning \u5165\u9580 \u8a00\u8a9e\u51e6\u7406100\u672c\u30ce\u30c3\u30af - Natural Language Processing (NLP) \u5165\u9580 arXivTimes/arXivTimes - \u8ad6\u6587\u306e Abstract \u8981\u7d04\u3092\u96c6\u3081\u305f\u30ea\u30dd\u30b8\u30c8\u30ea","title":"\u6559\u6750"},{"location":"Useful-Links/#datasets","text":"Food-101 zalandoresearch/fashion-mnist - FMNIST \u8863\u670d\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8 DataSets - arXivTimes/arXivTimes - \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u4e00\u89a7 ObjectNet - ImageNet \u3088\u308a\u96e3\u6613\u5ea6\u306e\u9ad8\u3044\u30c6\u30b9\u30c8\u7528\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8 Logo \u30ed\u30b4 msn199959/Logo-2k-plus-Dataset: Logo-2k-plus-Dataset LLD - Large Logo Dataset WebLogo-2M Dataset QMUL-OpenLogo Flickr Logos dataset | IVA Computer Vision Datasets","title":"Datasets"},{"location":"Useful-Links/#cnn_cnn-explainer","text":"live demo: CNN Explainer repo: poloclub/cnn-explainer: Learning Convolutional Neural Networks with Interactive Visualization. GIGAZINE: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u624b\u6cd5\u300cCNN\u300d\u306e\u753b\u50cf\u8b58\u5225\u51e6\u7406\u304c\u30a2\u30cb\u30e1\u30fc\u30b7\u30e7\u30f3\u3067\u7406\u89e3\u3067\u304d\u308b\u300cCNN Explainer\u300d - GIGAZINE","title":"CNN \u53ef\u8996\u5316 cnn-explainer"},{"location":"Useful-Links/#matplotlib","text":"matplotlib/cheatsheets: Official Matplotlib cheat sheets","title":"matplotlib"},{"location":"Useful-Links/#object_detection_model_list","text":"hoya012/deep_learning_object_detection: A paper list of object detection using deep learning.","title":"Object Detection Model List"},{"location":"Tutorial-Bing-Image-Search/","text":"Tutorial \u00b6 Bing Image Search API | Microsoft Azure Quickstart: Search for images using the Bing Image Search REST API and Python - Azure Cognitive Services | Microsoft Docs Start with docker-compose \u00b6 cd docs/Tutorial-Bing-Image-Search docker-compose build docker-compose run --rm dev bash Create your Subscription Key \u00b6 Go to Azure Create a Resource group Create a service of the Cognitive Services Check the latest information \u3053\u3053\u3089\u3078\u3093\u306e\u624b\u9806\u306f\u983b\u7e41\u306b\u5909\u308f\u308b\u306e\u3067\u516c\u5f0f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3092\u53c2\u7167\u3057\u3066\u6700\u65b0\u306e\u60c5\u5831\u3092\u78ba\u8a8d\u3059\u308b\u3053\u3068\u3002 \u3053\u3053\u3067\u306f\u89e3\u8aac\u3057\u306a\u3044\u3002 Check the latest official Azure documentation. Pricing - Bing Search API v7 | Microsoft Azure INSTANCE \u3092 Free \u3067\u4f5c\u6210\u3059\u308c\u3070 1000\u56de/\u6708 \u307e\u3067\u7121\u6599\u3067\u5229\u7528\u3067\u304d\u308b\u3002 Set Your Subscription Key \u00b6 Create your settings.ini . [azure] subscription_key = YOUR_KEY endpoint = https://YOUR_ENDPOINT.cognitiveservices.azure.com/bing/v7.0/images/search Make your subscription key private subscription_key \u3092\u9593\u9055\u3063\u3066 Git \u7ba1\u7406\u4e0b\u306b\u542b\u3081\u3066\u3001\u5168\u4e16\u754c\u306b\u5927\u516c\u958b\u3057\u306a\u3044\u3088\u3046\u306b\u6c17\u3092\u3064\u3051\u308b\u3053\u3068\u3002 \u8aa4\u3063\u3066\u516c\u958b\u3055\u308c\u3066\u3044\u308b\u30c8\u30fc\u30af\u30f3\u306f\u3059\u3050\u306b\u60aa\u7528\u3055\u308c\u307e\u3059\u3002 \u3061\u306a\u307f\u306b\u3053\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3067\u306f settings.ini \u306f .gitignore \u306b\u66f8\u304b\u308c\u3066\u3044\u307e\u3059\u3002 Run the main.py \u00b6 Show Usage \u00b6 python main.py --help Search Keyword \u00b6 python main.py -k 'cat' Skip donwloading images \u00b6 python main.py -k 'cat' --skip-downloading-images","title":"Tutorial"},{"location":"Tutorial-Bing-Image-Search/#tutorial","text":"Bing Image Search API | Microsoft Azure Quickstart: Search for images using the Bing Image Search REST API and Python - Azure Cognitive Services | Microsoft Docs","title":"Tutorial"},{"location":"Tutorial-Bing-Image-Search/#start_with_docker-compose","text":"cd docs/Tutorial-Bing-Image-Search docker-compose build docker-compose run --rm dev bash","title":"Start with docker-compose"},{"location":"Tutorial-Bing-Image-Search/#create_your_subscription_key","text":"Go to Azure Create a Resource group Create a service of the Cognitive Services Check the latest information \u3053\u3053\u3089\u3078\u3093\u306e\u624b\u9806\u306f\u983b\u7e41\u306b\u5909\u308f\u308b\u306e\u3067\u516c\u5f0f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3092\u53c2\u7167\u3057\u3066\u6700\u65b0\u306e\u60c5\u5831\u3092\u78ba\u8a8d\u3059\u308b\u3053\u3068\u3002 \u3053\u3053\u3067\u306f\u89e3\u8aac\u3057\u306a\u3044\u3002 Check the latest official Azure documentation. Pricing - Bing Search API v7 | Microsoft Azure INSTANCE \u3092 Free \u3067\u4f5c\u6210\u3059\u308c\u3070 1000\u56de/\u6708 \u307e\u3067\u7121\u6599\u3067\u5229\u7528\u3067\u304d\u308b\u3002","title":"Create your Subscription Key"},{"location":"Tutorial-Bing-Image-Search/#set_your_subscription_key","text":"Create your settings.ini . [azure] subscription_key = YOUR_KEY endpoint = https://YOUR_ENDPOINT.cognitiveservices.azure.com/bing/v7.0/images/search Make your subscription key private subscription_key \u3092\u9593\u9055\u3063\u3066 Git \u7ba1\u7406\u4e0b\u306b\u542b\u3081\u3066\u3001\u5168\u4e16\u754c\u306b\u5927\u516c\u958b\u3057\u306a\u3044\u3088\u3046\u306b\u6c17\u3092\u3064\u3051\u308b\u3053\u3068\u3002 \u8aa4\u3063\u3066\u516c\u958b\u3055\u308c\u3066\u3044\u308b\u30c8\u30fc\u30af\u30f3\u306f\u3059\u3050\u306b\u60aa\u7528\u3055\u308c\u307e\u3059\u3002 \u3061\u306a\u307f\u306b\u3053\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3067\u306f settings.ini \u306f .gitignore \u306b\u66f8\u304b\u308c\u3066\u3044\u307e\u3059\u3002","title":"Set Your Subscription Key"},{"location":"Tutorial-Bing-Image-Search/#run_the_mainpy","text":"","title":"Run the main.py"},{"location":"Tutorial-Bing-Image-Search/#show_usage","text":"python main.py --help","title":"Show Usage"},{"location":"Tutorial-Bing-Image-Search/#search_keyword","text":"python main.py -k 'cat'","title":"Search Keyword"},{"location":"Tutorial-Bing-Image-Search/#skip_donwloading_images","text":"python main.py -k 'cat' --skip-downloading-images","title":"Skip donwloading images"},{"location":"Tutorial-GitHub/","text":"Index \u00b6 \u5404\u7a2e\u8a2d\u5b9a","title":"Index"},{"location":"Tutorial-GitHub/#index","text":"\u5404\u7a2e\u8a2d\u5b9a","title":"Index"},{"location":"Tutorial-GitHub/packages/","text":"GitHub Packages \u00b6 Docker Login \u00b6 Create your personal token \u00b6 Personal Access Tokens \u3067 read:packages \u3092\u6301\u3064 token \u3092\u4f5c\u6210\u3059\u308b\u3002 Docker login \u00b6 docker login 'docker.pkg.github.com' -u 'YOUR_GITHUB_USERNAME' --password 'YOUR_TOKEN' \u3053\u308c\u3067 GitHub Packages \u304b\u3089 Docker image \u3092 Pull \u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308b\u3002","title":"GitHub Packages"},{"location":"Tutorial-GitHub/packages/#github_packages","text":"","title":"GitHub Packages"},{"location":"Tutorial-GitHub/packages/#docker_login","text":"","title":"Docker Login"},{"location":"Tutorial-GitHub/packages/#create_your_personal_token","text":"Personal Access Tokens \u3067 read:packages \u3092\u6301\u3064 token \u3092\u4f5c\u6210\u3059\u308b\u3002","title":"Create your personal token"},{"location":"Tutorial-GitHub/packages/#docker_login_1","text":"docker login 'docker.pkg.github.com' -u 'YOUR_GITHUB_USERNAME' --password 'YOUR_TOKEN' \u3053\u308c\u3067 GitHub Packages \u304b\u3089 Docker image \u3092 Pull \u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308b\u3002","title":"Docker login"},{"location":"Tutorial-GitHub/settings/","text":"Settings \u00b6 \u901a\u77e5\u3092\u30e1\u30fc\u30eb\u3067\u53d7\u3051\u53d6\u308b \u00b6 Settings -> Notifications \u3078\u30a2\u30af\u30bb\u30b9 \u4e0b\u8a18\u753b\u50cf\u306e\u3088\u3046\u306b\u8a2d\u5b9a\u3059\u308b \u3053\u308c\u3067\u901a\u77e5\u304c\u5bfe\u8c61\u306e\u30e1\u30fc\u30eb\u30a2\u30c9\u30ec\u30b9\u306b\u5c4a\u304f\u3088\u3046\u306b\u306a\u308b\u3002 \u901a\u77e5\u3092\u8a2d\u5b9a\u3059\u308b - GitHub \u30d8\u30eb\u30d7","title":"Settings"},{"location":"Tutorial-GitHub/settings/#settings","text":"","title":"Settings"},{"location":"Tutorial-GitHub/settings/#_1","text":"Settings -> Notifications \u3078\u30a2\u30af\u30bb\u30b9 \u4e0b\u8a18\u753b\u50cf\u306e\u3088\u3046\u306b\u8a2d\u5b9a\u3059\u308b \u3053\u308c\u3067\u901a\u77e5\u304c\u5bfe\u8c61\u306e\u30e1\u30fc\u30eb\u30a2\u30c9\u30ec\u30b9\u306b\u5c4a\u304f\u3088\u3046\u306b\u306a\u308b\u3002 \u901a\u77e5\u3092\u8a2d\u5b9a\u3059\u308b - GitHub \u30d8\u30eb\u30d7","title":"\u901a\u77e5\u3092\u30e1\u30fc\u30eb\u3067\u53d7\u3051\u53d6\u308b"},{"location":"Tutorial-PyTorch/","text":"Getting Started \u00b6 cd ./docs/Tutorial-PyTorch Login to GitHub Packages \u00b6 cf. Docekr login - GitHub Packages Docker run \u00b6 CPU \u00b6 Docker Compose # \u30b3\u30f3\u30c6\u30ca\u3092\u30d0\u30c3\u30af\u30b0\u30e9\u30a6\u30f3\u30c9\u3067\u8d77\u52d5 docker-compose up -d # \u30b3\u30f3\u30c6\u30ca\u306b\u30ed\u30b0\u30a4\u30f3 docker-compose exec dev bash # \u30b3\u30f3\u30c6\u30ca\u306e\u7d42\u4e86\u3068\u524a\u9664 docker-compose down GPU \u00b6 make run JupyterLab \u00b6 # \u30b3\u30f3\u30c6\u30ca\u5185 make lab","title":"Getting Started"},{"location":"Tutorial-PyTorch/#getting_started","text":"cd ./docs/Tutorial-PyTorch","title":"Getting Started"},{"location":"Tutorial-PyTorch/#login_to_github_packages","text":"cf. Docekr login - GitHub Packages","title":"Login to GitHub Packages"},{"location":"Tutorial-PyTorch/#docker_run","text":"","title":"Docker run"},{"location":"Tutorial-PyTorch/#cpu","text":"Docker Compose # \u30b3\u30f3\u30c6\u30ca\u3092\u30d0\u30c3\u30af\u30b0\u30e9\u30a6\u30f3\u30c9\u3067\u8d77\u52d5 docker-compose up -d # \u30b3\u30f3\u30c6\u30ca\u306b\u30ed\u30b0\u30a4\u30f3 docker-compose exec dev bash # \u30b3\u30f3\u30c6\u30ca\u306e\u7d42\u4e86\u3068\u524a\u9664 docker-compose down","title":"CPU"},{"location":"Tutorial-PyTorch/#gpu","text":"make run","title":"GPU"},{"location":"Tutorial-PyTorch/#jupyterlab","text":"# \u30b3\u30f3\u30c6\u30ca\u5185 make lab","title":"JupyterLab"},{"location":"Tutorial-PyTorch/transfer_learning/","text":"\u8ee2\u79fb\u5b66\u7fd2 \u00b6 Transfer Learning for Computer Vision Tutorial \u2014 PyTorch Tutorials 1.3.1 documentation \u5b66\u7fd2\u6e08\u307f ResNet18 \u3092\u7528\u3044\u3066\u8ee2\u79fb\u5b66\u7fd2\u3092\u3059\u308b\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3002 \u5168\u5c64\u3092\u518d\u5b66\u7fd2\u3059\u308b (Fine tuning \u3068\u547c\u3070\u308c\u308b) \u5168\u7d50\u5408\u5c64\u306e\u307f\u3092\u518d\u5b66\u7fd2\u3059\u308b (\u3053\u3063\u3061\u3092\u6307\u3057\u3066\u8ee2\u79fb\u5b66\u7fd2\u3068\u547c\u3076\u3053\u3068\u3082\u3042\u308b) Download dataset \u00b6 bash ./download_hymenoptera_data.sh Jupyter Lab \u00b6 notebook.ipynb \u3092 Jupyter Lab \u3067\u958b\u304f\u3002 Command line \u00b6 TBW.","title":"\u8ee2\u79fb\u5b66\u7fd2"},{"location":"Tutorial-PyTorch/transfer_learning/#_1","text":"Transfer Learning for Computer Vision Tutorial \u2014 PyTorch Tutorials 1.3.1 documentation \u5b66\u7fd2\u6e08\u307f ResNet18 \u3092\u7528\u3044\u3066\u8ee2\u79fb\u5b66\u7fd2\u3092\u3059\u308b\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3002 \u5168\u5c64\u3092\u518d\u5b66\u7fd2\u3059\u308b (Fine tuning \u3068\u547c\u3070\u308c\u308b) \u5168\u7d50\u5408\u5c64\u306e\u307f\u3092\u518d\u5b66\u7fd2\u3059\u308b (\u3053\u3063\u3061\u3092\u6307\u3057\u3066\u8ee2\u79fb\u5b66\u7fd2\u3068\u547c\u3076\u3053\u3068\u3082\u3042\u308b)","title":"\u8ee2\u79fb\u5b66\u7fd2"},{"location":"Tutorial-PyTorch/transfer_learning/#download_dataset","text":"bash ./download_hymenoptera_data.sh","title":"Download dataset"},{"location":"Tutorial-PyTorch/transfer_learning/#jupyter_lab","text":"notebook.ipynb \u3092 Jupyter Lab \u3067\u958b\u304f\u3002","title":"Jupyter Lab"},{"location":"Tutorial-PyTorch/transfer_learning/#command_line","text":"TBW.","title":"Command line"},{"location":"Tutorial-TensorFlow/","text":"Getting Started \u00b6 cd docs/Tutorial-TensorFlow Login to GitHub Packages \u00b6 cf. Docekr login - GitHub Packages Run Container \u00b6 CPU \u00b6 docker-compose # \u30b3\u30f3\u30c6\u30ca\u3092\u30d0\u30c3\u30af\u30b0\u30e9\u30a6\u30f3\u30c9\u3067\u8d77\u52d5 docker-compose up -d # \u30b3\u30f3\u30c6\u30ca\u306b\u30ed\u30b0\u30a4\u30f3 docker-compose exec dev bash # \u30b3\u30f3\u30c6\u30ca\u306e\u7d42\u4e86\u3068\u524a\u9664 docker-compose down GPU \u00b6 make run JupyterLab \u00b6 make lab","title":"Getting Started"},{"location":"Tutorial-TensorFlow/#getting_started","text":"cd docs/Tutorial-TensorFlow","title":"Getting Started"},{"location":"Tutorial-TensorFlow/#login_to_github_packages","text":"cf. Docekr login - GitHub Packages","title":"Login to GitHub Packages"},{"location":"Tutorial-TensorFlow/#run_container","text":"","title":"Run Container"},{"location":"Tutorial-TensorFlow/#cpu","text":"docker-compose # \u30b3\u30f3\u30c6\u30ca\u3092\u30d0\u30c3\u30af\u30b0\u30e9\u30a6\u30f3\u30c9\u3067\u8d77\u52d5 docker-compose up -d # \u30b3\u30f3\u30c6\u30ca\u306b\u30ed\u30b0\u30a4\u30f3 docker-compose exec dev bash # \u30b3\u30f3\u30c6\u30ca\u306e\u7d42\u4e86\u3068\u524a\u9664 docker-compose down","title":"CPU"},{"location":"Tutorial-TensorFlow/#gpu","text":"make run","title":"GPU"},{"location":"Tutorial-TensorFlow/#jupyterlab","text":"make lab","title":"JupyterLab"},{"location":"Tutorial-TensorFlow/Layers/","text":"Layers \u00b6 \u7573\u307f\u8fbc\u307f\u5c64 Convolutional Layer \u00b6 # tf.keras.layers.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', activation=None) input_shape = ( 4 , 5 , 5 , 3 ) # batch, I_h, I_w, channel x = tf . random . normal ( input_shape ) y = tf . keras . layers . Conv2D ( 2 , 3 , activation = 'relu' , input_shape = input_shape )( x ) print ( y . shape ) # (4, 3, 3, 2) # batch, O_h, O_w, filter \u30d7\u30fc\u30ea\u30f3\u30b0\u5c64 Pooling Layer \u00b6 # tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=None, padding='valid') input_shape = ( 4 , 5 , 5 , 3 ) # batch, I_h, I_w, channel x = tf . random . normal ( input_shape ) y = tf . keras . layers . MaxPooling2D ( pool_size = ( 2 , 2 ), strides = ( 1 , 1 ), padding = 'valid' )( x ) print ( y . shape ) # TensorShape([4, 4, 4, 3]) # batch, O_h, O_w, channel \u5168\u7d50\u5408\u5c64 Fully Connected Layer \u00b6 # tf.keras.layers.Dense(units, activation=None) input_shape = ( 4 , 3 , 3 , 2 ) # batch, I_h, I_w, channel x = tf . random . normal ( input_shape ) y = tf . keras . layers . Flatten ()( x ) print ( y . shape ) # TensorShape([1, 18]) out = tf . keras . layers . Dense ( 1 )( y ) print ( out . shape ) # TensorShape([1, 1]) # units \u30c9\u30ed\u30c3\u30d7\u30a2\u30a6\u30c8\u5c64 Dropout Layer \u00b6 # tf.keras.layers.Dropout(rate, noise_shape=None) x = tf . constant ([[ 1. , 2. , 3. ], [ 4. , 5. , 6. ], [ 7. , 8. , 9. ]]) layer = tf . keras . layers . Dropout ( 0.2 ) outputs = layer ( x , training = True ) outputs # <tf.Tensor: shape=(3, 3), dtype=float32, numpy= # array([[ 1.25, 2.5 , 3.75], # [ 5. , 6.25, 7.5 ], # [ 8.75, 10. , 0. ]], dtype=float32)> Note : \u30a4\u30f3\u30d7\u30c3\u30c8\u3092\u30e9\u30f3\u30c0\u30e0\u306b0\u306b\u3059\u308b(\u904e\u5b66\u7fd2\u9632\u6b62) \u5404\u30a4\u30f3\u30d7\u30c3\u30c8\u306b 1 / (1 - rate) \u304c\u52a0\u7b97\u3055\u308c\u308b","title":"Layers"},{"location":"Tutorial-TensorFlow/Layers/#layers","text":"","title":"Layers"},{"location":"Tutorial-TensorFlow/Layers/#convolutional_layer","text":"# tf.keras.layers.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', activation=None) input_shape = ( 4 , 5 , 5 , 3 ) # batch, I_h, I_w, channel x = tf . random . normal ( input_shape ) y = tf . keras . layers . Conv2D ( 2 , 3 , activation = 'relu' , input_shape = input_shape )( x ) print ( y . shape ) # (4, 3, 3, 2) # batch, O_h, O_w, filter","title":"\u7573\u307f\u8fbc\u307f\u5c64 Convolutional Layer"},{"location":"Tutorial-TensorFlow/Layers/#pooling_layer","text":"# tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=None, padding='valid') input_shape = ( 4 , 5 , 5 , 3 ) # batch, I_h, I_w, channel x = tf . random . normal ( input_shape ) y = tf . keras . layers . MaxPooling2D ( pool_size = ( 2 , 2 ), strides = ( 1 , 1 ), padding = 'valid' )( x ) print ( y . shape ) # TensorShape([4, 4, 4, 3]) # batch, O_h, O_w, channel","title":"\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64 Pooling Layer"},{"location":"Tutorial-TensorFlow/Layers/#fully_connected_layer","text":"# tf.keras.layers.Dense(units, activation=None) input_shape = ( 4 , 3 , 3 , 2 ) # batch, I_h, I_w, channel x = tf . random . normal ( input_shape ) y = tf . keras . layers . Flatten ()( x ) print ( y . shape ) # TensorShape([1, 18]) out = tf . keras . layers . Dense ( 1 )( y ) print ( out . shape ) # TensorShape([1, 1]) # units","title":"\u5168\u7d50\u5408\u5c64 Fully Connected Layer"},{"location":"Tutorial-TensorFlow/Layers/#dropout_layer","text":"# tf.keras.layers.Dropout(rate, noise_shape=None) x = tf . constant ([[ 1. , 2. , 3. ], [ 4. , 5. , 6. ], [ 7. , 8. , 9. ]]) layer = tf . keras . layers . Dropout ( 0.2 ) outputs = layer ( x , training = True ) outputs # <tf.Tensor: shape=(3, 3), dtype=float32, numpy= # array([[ 1.25, 2.5 , 3.75], # [ 5. , 6.25, 7.5 ], # [ 8.75, 10. , 0. ]], dtype=float32)> Note : \u30a4\u30f3\u30d7\u30c3\u30c8\u3092\u30e9\u30f3\u30c0\u30e0\u306b0\u306b\u3059\u308b(\u904e\u5b66\u7fd2\u9632\u6b62) \u5404\u30a4\u30f3\u30d7\u30c3\u30c8\u306b 1 / (1 - rate) \u304c\u52a0\u7b97\u3055\u308c\u308b","title":"\u30c9\u30ed\u30c3\u30d7\u30a2\u30a6\u30c8\u5c64 Dropout Layer"},{"location":"Tutorial-TensorFlow/data-augmentation/","text":"Data Augmentation \u00b6 Data augmentation | TensorFlow Core \u4e0b\u306e\u753b\u50cf\u3092\u5143\u306b\u30c7\u30fc\u30bf\u3092\u62e1\u5f35\u3002 \u5168\u4f53\u306e\u30b3\u30fc\u30c9\u306f augmentation.py \u306b\u8a18\u8f09\u3002 Import libraries \u00b6 import tensorflow as tf import matplotlib.pyplot as plt import matplotlib as mpl mpl . rcParams [ 'figure.figsize' ] = ( 12 , 5 ) Read an image \u00b6 image_dir_path = \"images/\" image_name = \"squirrel.jpg\" image_string = tf . io . read_file ( image_dir_path + image_name ) image = tf . image . decode_jpeg ( image_string , channels = 3 ) show images \u00b6 \u30aa\u30ea\u30b8\u30ca\u30eb\u753b\u50cf\u3068\u62e1\u5f35\u5f8c\u306e\u753b\u50cf\u3092\u898b\u6bd4\u3079\u308b\u305f\u3081\u306e\u95a2\u6570\u3002 def visualize ( original , augmented , filename ): fig = plt . figure () plt . subplot ( 1 , 2 , 1 ) plt . title ( 'Original image' ) plt . imshow ( original ) plt . subplot ( 1 , 2 , 2 ) plt . title ( 'Augmented image' ) plt . imshow ( augmented ) plt . savefig ( image_dir_path + filename ) Flip Horizontally \u00b6 \u753b\u50cf\u3092\u5de6\u53f3\u53cd\u8ee2\u3055\u305b\u308b\u3002 # tf.image.flip_left_right(image) flipped = tf . image . flip_left_right ( image ) visualize ( image , flipped , \"flipped.jpg\" ) Flip Vertically \u00b6 \u753b\u50cf\u3092\u4e0a\u4e0b\u53cd\u8ee2\u3055\u305b\u308b\u3002 # tf.image.flip_up_down(image) flipped = tf . image . flip_up_down ( image ) visualize ( image , flipped , \"flipped_up_down.jpg\" ) grayscale \u00b6 \u753b\u50cf\u3092\u30b0\u30ec\u30a4\u30b9\u30b1\u30fc\u30eb\u306b\u3059\u308b\u3002 # tf.image.rgb_to_grayscale(images, name=None) grayscaled = tf . image . rgb_to_grayscale ( image ) visualize ( image , tf . squeeze ( grayscaled ), \"grayscaled.jpg\" ) print ( image . shape ) print ( grayscaled . shape ) # (1066, 1600, 3) # (1066, 1600, 1) saturation \u00b6 \u753b\u50cf\u306e\u5f69\u5ea6\u3092\u8abf\u6574\u3059\u308b\u3002 \u753b\u50cf\u3092 HSV \u306b\u5909\u63db\u3057\u305f\u5f8c\u3001\u5f69\u5ea6(S) \u306b saturation_factor \u3092\u4e57\u7b97\u3057\u3066\u307e\u305f RGB \u306b\u623b\u3059\u3002 # tf.image.adjust_saturation(image, saturation_factor, name=None) saturated = tf . image . adjust_saturation ( image , 3 ) visualize ( image , saturated , \"saturated.jpg\" ) brightness \u00b6 \u753b\u50cf\u306e\u8f1d\u5ea6\u3092\u8abf\u6574\u3059\u308b\u3002 \u753b\u50cf\u3092 [0,1] \u306e\u6d6e\u52d5\u5c0f\u6570\u578b\u306b\u5909\u63db\u3057\u305f\u5f8c\u3001 delta \u3092\u5404\u753b\u7d20\u306b\u52a0\u7b97\u3059\u308b\u3002\u52a0\u7b97\u304c\u7d42\u4e86\u3057\u305f\u3089\u5143\u306e\u30c7\u30fc\u30bf\u578b\u306b\u623b\u3059\u3002 #tf.image.adjust_brightness(image, delta) bright = tf . image . adjust_brightness ( image , 0.4 ) visualize ( image , bright , \"bright.jpg\" ) Rotation \u00b6 \u753b\u50cf\u3092 k * 90\u00b0 \u56de\u8ee2\u3055\u305b\u308b\u3002 # tf.image.rot90(image, k=1, name=None) rotated = tf . image . rot90 ( image , k = 1 ) visualize ( image , rotated , \"rotated.jpg\" ) Crop the central region \u00b6 \u753b\u50cf\u3092\u4e2d\u592e\u304b\u3089 central_fraction * 100% \u5207\u308a\u629c\u304f\u3002 # tf.image.central_crop(image, central_fraction) cropped = tf . image . central_crop ( image , central_fraction = 0.5 ) visualize ( image , cropped , \"cropped.jpg\" ) Apply a data augmentation randomly \u00b6 \u30e9\u30f3\u30c0\u30e0\u306b\u30c7\u30fc\u30bf\u62e1\u5f35\u3092\u9069\u7528\u3059\u308b\u3002 \u62e1\u5f35\u306e\u65b9\u6cd5\u3092\u95a2\u6570\u306b\u3057\u3066\u304a\u304d\u3001\u6bce\u56de\u30e9\u30f3\u30c0\u30e0\u306b\u305d\u308c\u3089\u306e\u95a2\u6570\u3092\u9078\u3076\u3088\u3046\u306a\u51e6\u7406\u3002 def flip ( image ): return tf . image . flip_left_right ( image ) def grayscale ( image ): return tf . image . rgb_to_grayscale ( image ) def saturate ( image ): return tf . image . adjust_saturation ( image , 3 ) def bright ( image ): return tf . image . adjust_brightness ( image , 0.4 ) def rotate ( image ): return tf . image . rot90 ( image , k = 1 ) def crop ( image ): return tf . image . central_crop ( image , central_fraction = 0.5 ) funcs = [ flip , grayscale , saturate , bright , rotate , crop ] num = list ( range ( len ( funcs ))) for i in range ( random . randrange ( 1 , 3 )): chosen = random . choice ( num ) image = random . choice [ funcs ]( image ) num . remove ( chosen ) cifar10.py \u3067\u6c34\u5897\u3057\u3042\u308a\u30fb\u306a\u3057\u306e\u6bd4\u8f03\u3092\u3057\u3066\u307f\u308b\u3068\u3088\u3044\u3002 python cifar10.py Others \u00b6 Image augmentation library \u306e albumentations \u3068\u3044\u3046\u3082\u306e\u3082\u3042\u308b\u3002 albumentations-team/albumentations: fast image augmentation library and easy to use wrapper around other libraries","title":"Data Augmentation"},{"location":"Tutorial-TensorFlow/data-augmentation/#data_augmentation","text":"Data augmentation | TensorFlow Core \u4e0b\u306e\u753b\u50cf\u3092\u5143\u306b\u30c7\u30fc\u30bf\u3092\u62e1\u5f35\u3002 \u5168\u4f53\u306e\u30b3\u30fc\u30c9\u306f augmentation.py \u306b\u8a18\u8f09\u3002","title":"Data Augmentation"},{"location":"Tutorial-TensorFlow/data-augmentation/#import_libraries","text":"import tensorflow as tf import matplotlib.pyplot as plt import matplotlib as mpl mpl . rcParams [ 'figure.figsize' ] = ( 12 , 5 )","title":"Import libraries"},{"location":"Tutorial-TensorFlow/data-augmentation/#read_an_image","text":"image_dir_path = \"images/\" image_name = \"squirrel.jpg\" image_string = tf . io . read_file ( image_dir_path + image_name ) image = tf . image . decode_jpeg ( image_string , channels = 3 )","title":"Read an image"},{"location":"Tutorial-TensorFlow/data-augmentation/#show_images","text":"\u30aa\u30ea\u30b8\u30ca\u30eb\u753b\u50cf\u3068\u62e1\u5f35\u5f8c\u306e\u753b\u50cf\u3092\u898b\u6bd4\u3079\u308b\u305f\u3081\u306e\u95a2\u6570\u3002 def visualize ( original , augmented , filename ): fig = plt . figure () plt . subplot ( 1 , 2 , 1 ) plt . title ( 'Original image' ) plt . imshow ( original ) plt . subplot ( 1 , 2 , 2 ) plt . title ( 'Augmented image' ) plt . imshow ( augmented ) plt . savefig ( image_dir_path + filename )","title":"show images"},{"location":"Tutorial-TensorFlow/data-augmentation/#flip_horizontally","text":"\u753b\u50cf\u3092\u5de6\u53f3\u53cd\u8ee2\u3055\u305b\u308b\u3002 # tf.image.flip_left_right(image) flipped = tf . image . flip_left_right ( image ) visualize ( image , flipped , \"flipped.jpg\" )","title":"Flip Horizontally"},{"location":"Tutorial-TensorFlow/data-augmentation/#flip_vertically","text":"\u753b\u50cf\u3092\u4e0a\u4e0b\u53cd\u8ee2\u3055\u305b\u308b\u3002 # tf.image.flip_up_down(image) flipped = tf . image . flip_up_down ( image ) visualize ( image , flipped , \"flipped_up_down.jpg\" )","title":"Flip Vertically"},{"location":"Tutorial-TensorFlow/data-augmentation/#grayscale","text":"\u753b\u50cf\u3092\u30b0\u30ec\u30a4\u30b9\u30b1\u30fc\u30eb\u306b\u3059\u308b\u3002 # tf.image.rgb_to_grayscale(images, name=None) grayscaled = tf . image . rgb_to_grayscale ( image ) visualize ( image , tf . squeeze ( grayscaled ), \"grayscaled.jpg\" ) print ( image . shape ) print ( grayscaled . shape ) # (1066, 1600, 3) # (1066, 1600, 1)","title":"grayscale"},{"location":"Tutorial-TensorFlow/data-augmentation/#saturation","text":"\u753b\u50cf\u306e\u5f69\u5ea6\u3092\u8abf\u6574\u3059\u308b\u3002 \u753b\u50cf\u3092 HSV \u306b\u5909\u63db\u3057\u305f\u5f8c\u3001\u5f69\u5ea6(S) \u306b saturation_factor \u3092\u4e57\u7b97\u3057\u3066\u307e\u305f RGB \u306b\u623b\u3059\u3002 # tf.image.adjust_saturation(image, saturation_factor, name=None) saturated = tf . image . adjust_saturation ( image , 3 ) visualize ( image , saturated , \"saturated.jpg\" )","title":"saturation"},{"location":"Tutorial-TensorFlow/data-augmentation/#brightness","text":"\u753b\u50cf\u306e\u8f1d\u5ea6\u3092\u8abf\u6574\u3059\u308b\u3002 \u753b\u50cf\u3092 [0,1] \u306e\u6d6e\u52d5\u5c0f\u6570\u578b\u306b\u5909\u63db\u3057\u305f\u5f8c\u3001 delta \u3092\u5404\u753b\u7d20\u306b\u52a0\u7b97\u3059\u308b\u3002\u52a0\u7b97\u304c\u7d42\u4e86\u3057\u305f\u3089\u5143\u306e\u30c7\u30fc\u30bf\u578b\u306b\u623b\u3059\u3002 #tf.image.adjust_brightness(image, delta) bright = tf . image . adjust_brightness ( image , 0.4 ) visualize ( image , bright , \"bright.jpg\" )","title":"brightness"},{"location":"Tutorial-TensorFlow/data-augmentation/#rotation","text":"\u753b\u50cf\u3092 k * 90\u00b0 \u56de\u8ee2\u3055\u305b\u308b\u3002 # tf.image.rot90(image, k=1, name=None) rotated = tf . image . rot90 ( image , k = 1 ) visualize ( image , rotated , \"rotated.jpg\" )","title":"Rotation"},{"location":"Tutorial-TensorFlow/data-augmentation/#crop_the_central_region","text":"\u753b\u50cf\u3092\u4e2d\u592e\u304b\u3089 central_fraction * 100% \u5207\u308a\u629c\u304f\u3002 # tf.image.central_crop(image, central_fraction) cropped = tf . image . central_crop ( image , central_fraction = 0.5 ) visualize ( image , cropped , \"cropped.jpg\" )","title":"Crop the central region"},{"location":"Tutorial-TensorFlow/data-augmentation/#apply_a_data_augmentation_randomly","text":"\u30e9\u30f3\u30c0\u30e0\u306b\u30c7\u30fc\u30bf\u62e1\u5f35\u3092\u9069\u7528\u3059\u308b\u3002 \u62e1\u5f35\u306e\u65b9\u6cd5\u3092\u95a2\u6570\u306b\u3057\u3066\u304a\u304d\u3001\u6bce\u56de\u30e9\u30f3\u30c0\u30e0\u306b\u305d\u308c\u3089\u306e\u95a2\u6570\u3092\u9078\u3076\u3088\u3046\u306a\u51e6\u7406\u3002 def flip ( image ): return tf . image . flip_left_right ( image ) def grayscale ( image ): return tf . image . rgb_to_grayscale ( image ) def saturate ( image ): return tf . image . adjust_saturation ( image , 3 ) def bright ( image ): return tf . image . adjust_brightness ( image , 0.4 ) def rotate ( image ): return tf . image . rot90 ( image , k = 1 ) def crop ( image ): return tf . image . central_crop ( image , central_fraction = 0.5 ) funcs = [ flip , grayscale , saturate , bright , rotate , crop ] num = list ( range ( len ( funcs ))) for i in range ( random . randrange ( 1 , 3 )): chosen = random . choice ( num ) image = random . choice [ funcs ]( image ) num . remove ( chosen ) cifar10.py \u3067\u6c34\u5897\u3057\u3042\u308a\u30fb\u306a\u3057\u306e\u6bd4\u8f03\u3092\u3057\u3066\u307f\u308b\u3068\u3088\u3044\u3002 python cifar10.py","title":"Apply a data augmentation randomly"},{"location":"Tutorial-TensorFlow/data-augmentation/#others","text":"Image augmentation library \u306e albumentations \u3068\u3044\u3046\u3082\u306e\u3082\u3042\u308b\u3002 albumentations-team/albumentations: fast image augmentation library and easy to use wrapper around other libraries","title":"Others"},{"location":"Tutorial-TensorFlow/k-fold-cross-validation/","text":"K-fold cross-validation \u00b6 tf.data.Dataset | Tensorflow Core \u65e5\u672c\u8a9e\u3060\u3068 K-\u5206\u5272\u4ea4\u5dee\u691c\u8a3c \u3002\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092 K \u500b\u306b\u5206\u5272\u3057\u3066K - 1\u500b\u3092 training set \u3001\u6b8b\u308a\u306e1\u500b\u3092 validation set \u3068\u3059\u308b\u3002\u4ea4\u5dee\u691c\u8a3c\u3092\u884c\u3046\u3053\u3068\u3067\u3001\u30e2\u30c7\u30eb\u306e\u6c4e\u5316\u6027\u80fd\u3092\u78ba\u8a8d\u3059\u308b\u3002\u6700\u7d42\u7684\u306a\u30e2\u30c7\u30eb\u306e\u8a55\u4fa1\u3068\u3057\u3066\u306f\u3001K\u500b\u305d\u308c\u305e\u308c\u306e\u30e2\u30c7\u30eb\u3067\u7cbe\u5ea6\u3092\u8a08\u7b97\u3057\u3001\u305d\u308c\u3089\u306e\u5e73\u5747\u3092\u53d6\u308b\u306e\u304c\u4e00\u822c\u7684\u3067\u3042\u308b\u3002 \u3053\u3053\u3067\u306f\u3001\u5206\u5272\u6642\u306b\u4f7f\u7528\u3057\u305f\u4e3b\u306a\u30e1\u30be\u30c3\u30c8\u3092\u7d39\u4ecb\u3059\u308b\u3002 \u5168\u4f53\u30b3\u30fc\u30c9\u306f K_fold_cross_validation.py \u306b\u8a18\u8f09\u3002 take \u00b6 tf.data.Dataset \u578b\u306e\u3068\u304d\u4f7f\u7528\u3067\u304d\u3001 count \u307e\u3067\u306e\u30c7\u30fc\u30bf\u3092\u53d6\u5f97\u3059\u308b\u3002 # take(count) dataset = tf . data . Dataset . range ( 10 ) dataset = dataset . take ( 3 ) list ( dataset . as_numpy_iterator ()) # [0, 1, 2] skip \u00b6 tf.data.Dataset \u578b\u306e\u3068\u304d\u4f7f\u7528\u3067\u304d\u3001 count \u307e\u3067\u306e\u30c7\u30fc\u30bf\u3092\u30b9\u30ad\u30c3\u30d7\u3059\u308b\u3002 # skip(count) dataset = tf . data . Dataset . range ( 10 ) dataset = dataset . skip ( 7 ) list ( dataset . as_numpy_iterator ()) # [7, 8, 9] concatenate \u00b6 tf.data.Dataset \u578b\u540c\u58eb\u3092\u7d50\u5408\u3059\u308b\u3002 # concatenate(dataset) a = tf . data . Dataset . range ( 1 , 3 ) # ==> [1, 2] b = tf . data . Dataset . range ( 3 , 6 ) # ==> [3, 4, 5] ds = a . concatenate ( b ) list ( ds . as_numpy_iterator ()) # [1, 2, 3, 4, 5]","title":"K-fold cross-validation"},{"location":"Tutorial-TensorFlow/k-fold-cross-validation/#k-fold_cross-validation","text":"tf.data.Dataset | Tensorflow Core \u65e5\u672c\u8a9e\u3060\u3068 K-\u5206\u5272\u4ea4\u5dee\u691c\u8a3c \u3002\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092 K \u500b\u306b\u5206\u5272\u3057\u3066K - 1\u500b\u3092 training set \u3001\u6b8b\u308a\u306e1\u500b\u3092 validation set \u3068\u3059\u308b\u3002\u4ea4\u5dee\u691c\u8a3c\u3092\u884c\u3046\u3053\u3068\u3067\u3001\u30e2\u30c7\u30eb\u306e\u6c4e\u5316\u6027\u80fd\u3092\u78ba\u8a8d\u3059\u308b\u3002\u6700\u7d42\u7684\u306a\u30e2\u30c7\u30eb\u306e\u8a55\u4fa1\u3068\u3057\u3066\u306f\u3001K\u500b\u305d\u308c\u305e\u308c\u306e\u30e2\u30c7\u30eb\u3067\u7cbe\u5ea6\u3092\u8a08\u7b97\u3057\u3001\u305d\u308c\u3089\u306e\u5e73\u5747\u3092\u53d6\u308b\u306e\u304c\u4e00\u822c\u7684\u3067\u3042\u308b\u3002 \u3053\u3053\u3067\u306f\u3001\u5206\u5272\u6642\u306b\u4f7f\u7528\u3057\u305f\u4e3b\u306a\u30e1\u30be\u30c3\u30c8\u3092\u7d39\u4ecb\u3059\u308b\u3002 \u5168\u4f53\u30b3\u30fc\u30c9\u306f K_fold_cross_validation.py \u306b\u8a18\u8f09\u3002","title":"K-fold cross-validation"},{"location":"Tutorial-TensorFlow/k-fold-cross-validation/#take","text":"tf.data.Dataset \u578b\u306e\u3068\u304d\u4f7f\u7528\u3067\u304d\u3001 count \u307e\u3067\u306e\u30c7\u30fc\u30bf\u3092\u53d6\u5f97\u3059\u308b\u3002 # take(count) dataset = tf . data . Dataset . range ( 10 ) dataset = dataset . take ( 3 ) list ( dataset . as_numpy_iterator ()) # [0, 1, 2]","title":"take"},{"location":"Tutorial-TensorFlow/k-fold-cross-validation/#skip","text":"tf.data.Dataset \u578b\u306e\u3068\u304d\u4f7f\u7528\u3067\u304d\u3001 count \u307e\u3067\u306e\u30c7\u30fc\u30bf\u3092\u30b9\u30ad\u30c3\u30d7\u3059\u308b\u3002 # skip(count) dataset = tf . data . Dataset . range ( 10 ) dataset = dataset . skip ( 7 ) list ( dataset . as_numpy_iterator ()) # [7, 8, 9]","title":"skip"},{"location":"Tutorial-TensorFlow/k-fold-cross-validation/#concatenate","text":"tf.data.Dataset \u578b\u540c\u58eb\u3092\u7d50\u5408\u3059\u308b\u3002 # concatenate(dataset) a = tf . data . Dataset . range ( 1 , 3 ) # ==> [1, 2] b = tf . data . Dataset . range ( 3 , 6 ) # ==> [3, 4, 5] ds = a . concatenate ( b ) list ( ds . as_numpy_iterator ()) # [1, 2, 3, 4, 5]","title":"concatenate"},{"location":"Tutorial-TensorFlow/original-network/","text":"Original Network \u00b6 TensorFlow \u3092\u4f7f\u7528\u3057\u3066\u30aa\u30ea\u30b8\u30ca\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u69cb\u7bc9\u3002MNIST \u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\u30fb\u63a8\u8ad6\u3092\u884c\u3046\u3002 \u5168\u4f53\u306e\u30b3\u30fc\u30c9\u306f mnist.py \u306b\u8a18\u8f09\u3002 Import Libralies \u00b6 from __future__ import absolute_import , division , print_function , unicode_literals import tensorflow as tf from tensorflow.keras import datasets from tensorflow.keras.layers import Dense , Flatten , Conv2D , MaxPooling2D , Dropout from tensorflow.keras import Sequential Parameters \u00b6 \u30a8\u30dd\u30c3\u30af\u6570\u3068\u30d0\u30c3\u30c1\u6570\u3092\u8a2d\u5b9a\u3002 EPOCH = 5 BATCH = 64 Network \u00b6 \u4f7f\u7528\u3059\u308b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u5168\u4f53\u50cf\u3002\u5404\u5c64\u306b\u3064\u3044\u3066\u306f Layers \u3092\u53c2\u7167\u3002 model = Sequential ([ Conv2D ( 64 , 3 , activation = 'relu' , input_shape = ( 28 , 28 , 1 )), Conv2D ( 64 , 3 , activation = 'relu' ), MaxPooling2D (), Dropout ( 0.2 ), Conv2D ( 64 , 3 , activation = 'relu' ), Conv2D ( 64 , 3 , activation = 'relu' ), MaxPooling2D (), Dropout ( 0.2 ), Flatten (), Dense ( 512 , activation = 'relu' ), Dense ( 10 , activation = 'softmax' ) ]) Download mnint \u00b6 mnist \u3092\u30b9\u30af\u30ea\u30d7\u30c8\u5185\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\u3002 mnist = datasets . mnist ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () Preprocessing \u00b6 \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3067\u4f7f\u7528\u3059\u308b\u305f\u3081\u306b reshape \u3059\u308b\u3002 train_images = train_images . reshape (( 60000 , 28 , 28 , 1 )) test_images = test_images . reshape (( 10000 , 28 , 28 , 1 )) \u753b\u50cf\u30c7\u30fc\u30bf\u306e\u305f\u3081 255 \u3067\u9664\u7b97\u3057\u3066\u6b63\u898f\u5316\u3059\u308b\u3002 train_images = train_images / 255.0 test_images = test_images / 255.0 Compile and Train \u00b6 model . compile ( optimizer = 'adam' , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ]) model . fit ( x = train_images , y = train_labels , steps_per_epoch = len ( train_images ) // BATCH , batch_size = BATCH , epochs = EPOCH ) Test the model \u00b6 test_loss , test_acc = model . evaluate ( x = test_images , y = test_labels , batch_size = 1 , verbose = 1 ) Run the mnist.py \u00b6 python3 mnist . py ## train info Epoch 1 / 5 937 / 937 [ ============================== ] - 5 s 5 ms / step - loss : 0.1384 - accuracy : 0.9557 Epoch 2 / 5 937 / 937 [ ============================== ] - 5 s 5 ms / step - loss : 0.0435 - accuracy : 0.9869 Epoch 3 / 5 937 / 937 [ ============================== ] - 5 s 5 ms / step - loss : 0.0322 - accuracy : 0.9896 Epoch 4 / 5 937 / 937 [ ============================== ] - 5 s 5 ms / step - loss : 0.0267 - accuracy : 0.9915 Epoch 5 / 5 937 / 937 [ ============================== ] - 5 s 5 ms / step - loss : 0.0213 - accuracy : 0.9934 ## test info 10000 / 10000 [ ============================== ] - 22 s 2 ms / step - loss : 0.0231 - accuracy : 0.9928 Test data \u306b\u5bfe\u3057\u3066 99.28% \u3092\u9054\u6210\u3002","title":"Original Network"},{"location":"Tutorial-TensorFlow/original-network/#original_network","text":"TensorFlow \u3092\u4f7f\u7528\u3057\u3066\u30aa\u30ea\u30b8\u30ca\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u69cb\u7bc9\u3002MNIST \u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\u30fb\u63a8\u8ad6\u3092\u884c\u3046\u3002 \u5168\u4f53\u306e\u30b3\u30fc\u30c9\u306f mnist.py \u306b\u8a18\u8f09\u3002","title":"Original Network"},{"location":"Tutorial-TensorFlow/original-network/#import_libralies","text":"from __future__ import absolute_import , division , print_function , unicode_literals import tensorflow as tf from tensorflow.keras import datasets from tensorflow.keras.layers import Dense , Flatten , Conv2D , MaxPooling2D , Dropout from tensorflow.keras import Sequential","title":"Import Libralies"},{"location":"Tutorial-TensorFlow/original-network/#parameters","text":"\u30a8\u30dd\u30c3\u30af\u6570\u3068\u30d0\u30c3\u30c1\u6570\u3092\u8a2d\u5b9a\u3002 EPOCH = 5 BATCH = 64","title":"Parameters"},{"location":"Tutorial-TensorFlow/original-network/#network","text":"\u4f7f\u7528\u3059\u308b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u5168\u4f53\u50cf\u3002\u5404\u5c64\u306b\u3064\u3044\u3066\u306f Layers \u3092\u53c2\u7167\u3002 model = Sequential ([ Conv2D ( 64 , 3 , activation = 'relu' , input_shape = ( 28 , 28 , 1 )), Conv2D ( 64 , 3 , activation = 'relu' ), MaxPooling2D (), Dropout ( 0.2 ), Conv2D ( 64 , 3 , activation = 'relu' ), Conv2D ( 64 , 3 , activation = 'relu' ), MaxPooling2D (), Dropout ( 0.2 ), Flatten (), Dense ( 512 , activation = 'relu' ), Dense ( 10 , activation = 'softmax' ) ])","title":"Network"},{"location":"Tutorial-TensorFlow/original-network/#download_mnint","text":"mnist \u3092\u30b9\u30af\u30ea\u30d7\u30c8\u5185\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\u3002 mnist = datasets . mnist ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data ()","title":"Download mnint"},{"location":"Tutorial-TensorFlow/original-network/#preprocessing","text":"\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3067\u4f7f\u7528\u3059\u308b\u305f\u3081\u306b reshape \u3059\u308b\u3002 train_images = train_images . reshape (( 60000 , 28 , 28 , 1 )) test_images = test_images . reshape (( 10000 , 28 , 28 , 1 )) \u753b\u50cf\u30c7\u30fc\u30bf\u306e\u305f\u3081 255 \u3067\u9664\u7b97\u3057\u3066\u6b63\u898f\u5316\u3059\u308b\u3002 train_images = train_images / 255.0 test_images = test_images / 255.0","title":"Preprocessing"},{"location":"Tutorial-TensorFlow/original-network/#compile_and_train","text":"model . compile ( optimizer = 'adam' , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ]) model . fit ( x = train_images , y = train_labels , steps_per_epoch = len ( train_images ) // BATCH , batch_size = BATCH , epochs = EPOCH )","title":"Compile and Train"},{"location":"Tutorial-TensorFlow/original-network/#test_the_model","text":"test_loss , test_acc = model . evaluate ( x = test_images , y = test_labels , batch_size = 1 , verbose = 1 )","title":"Test the model"},{"location":"Tutorial-TensorFlow/original-network/#run_the_mnistpy","text":"python3 mnist . py ## train info Epoch 1 / 5 937 / 937 [ ============================== ] - 5 s 5 ms / step - loss : 0.1384 - accuracy : 0.9557 Epoch 2 / 5 937 / 937 [ ============================== ] - 5 s 5 ms / step - loss : 0.0435 - accuracy : 0.9869 Epoch 3 / 5 937 / 937 [ ============================== ] - 5 s 5 ms / step - loss : 0.0322 - accuracy : 0.9896 Epoch 4 / 5 937 / 937 [ ============================== ] - 5 s 5 ms / step - loss : 0.0267 - accuracy : 0.9915 Epoch 5 / 5 937 / 937 [ ============================== ] - 5 s 5 ms / step - loss : 0.0213 - accuracy : 0.9934 ## test info 10000 / 10000 [ ============================== ] - 22 s 2 ms / step - loss : 0.0231 - accuracy : 0.9928 Test data \u306b\u5bfe\u3057\u3066 99.28% \u3092\u9054\u6210\u3002","title":"Run the mnist.py"},{"location":"Tutorial-TensorFlow-Models/","text":"Tutorial \u00b6 Inception v2 base SSD 300 \u306e\u8ee2\u79fb\u5b66\u7fd2 (Transfer Learning) tensorflow/models: Models and examples built with TensorFlow Tensorflow Object Detection API v1.13.0 Installation - Tensorflow Object Detection API v1.13.0 model zoo - Tensorflow Object Detection API v1.13.0 Prepare dataset \u00b6 train val \u00b6 .tfrecord \u3092\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u914d\u7f6e\u3002 data/train : \u6559\u5e2b\u30c7\u30fc\u30bf data/val : \u691c\u8a3c\u30c7\u30fc\u30bf $ tree data data \u251c\u2500\u2500 change_tfrecord_filename.sh \u251c\u2500\u2500 cat-TFRecords-export \u251c\u2500\u2500 tf_label_map.pbtxt \u251c\u2500\u2500 train \u2502 \u251c\u2500\u2500 frame-fa9aee7507d749368eaea01fde15dc0f.tfrecord \u2502 \u251c\u2500\u2500 frame-fb52802ac5fb1d0e4465c535603cc8d1.tfrecord \u2502 \u251c\u2500\u2500 frame-fcca1acaa65736d0632a4c9d09f46f34.tfrecord ... \u2502 \u2514\u2500\u2500 frame-fe032dbfda72e3a42d0a9b00b62695fe.tfrecord \u2514\u2500\u2500 val \u251c\u2500\u2500 frame-fe8158671dbeda266efea62af20d7e97.tfrecord \u251c\u2500\u2500 frame-ffef9a9882b57f2c6124c889a3ec9afd.tfrecord \u251c\u2500\u2500 frame-ffef9a9882b57f2c6124c889a3ec9afd.tfrecord ... cat-TFRecords-export \u306b\u3059\u3079\u3066\u306e tfrecord \u304c\u5165\u3063\u3066\u3044\u308b\u3082\u306e\u3068\u3057\u3066\u3001 cd docs/Tutorial-TensorFlow-Models/data bash ./change_tfrecord_filename.sh cat-TFRecords-export \u3042\u3068\u306f train \u3068 val \u306b tfrecord \u3092\u5206\u3051\u3066\u914d\u7f6e\u3059\u308b\u3002 tf_label_map.pbtxt \u00b6 item { id: 1 name: 'cat' } config \u00b6 config/ssd_inception_v2_coco.config \u3092\u7de8\u96c6\u3059\u308b\u3053\u3068\u3067\u524d\u51e6\u7406 (data augmentation) \u3092\u8ffd\u52a0\u30fb\u524a\u9664\u3067\u304d\u308b\u3002 \u305d\u306e\u4ed6 batch size, learning rate \u306a\u3069\u306e\u8a2d\u5b9a\u3082\u3053\u3053\u3067\u6307\u5b9a\u3067\u304d\u308b\u3002 Build Docker image \u00b6 cd docs/Tutorial-TensorFlow-Models # Build make build Run Container \u00b6 make run \u30b3\u30f3\u30c6\u30ca\u306b\u30ed\u30b0\u30a4\u30f3\u3057\u305f\u3089\u4ee5\u4e0b\u3092\u6bce\u56de\u5b9f\u884c\u3059\u308b\u3002 cd ~/models/research export PYTHONPATH = ${ PYTHONPATH } : $( pwd ) : $( pwd ) /slim \u52d5\u4f5c\u30c6\u30b9\u30c8 cd ~/models/research python3 ./object_detection/builders/model_builder_test.py Train \u00b6 \u30db\u30b9\u30c8\u30de\u30b7\u30f3\u3067\u516c\u958b\u3055\u308c\u3066\u3044\u308b\u4e8b\u524d\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3002 cd models bash get_ssd_inception_v2_coco_model.sh \u30b3\u30f3\u30c6\u30ca\u5185\u3002 nohup python3 ./object_detection/model_main.py \\ --pipeline_config_path = \"./object_detection_tools/config/ssd_inception_v2_coco.config\" \\ --model_dir = \"./object_detection_tools/saved_model/cat_01\" \\ --num_train_steps = 20000 \\ --alsologtostderr > ./object_detection_tools/nohup.log & ctrl+p+q \u3067\u30b3\u30f3\u30c6\u30ca\u304b\u3089\u629c\u3051\u308b\u3002 Tensorboard \u00b6 cd docs/Tutorial-TensorFlow-Models/tensorboard docker build . -t tensorboard:latest docker run --rm -it -v ${ PWD } /saved_model/cat_01:/logs -p 6006 :6006 --network host --name tensorboard tensorboard:latest \u30e2\u30c7\u30eb\u5909\u63db \u00b6 \u30b3\u30f3\u30c6\u30ca\u5185\u3002 python3 ./object_detection/export_inference_graph.py \\ --input_type image_tensor \\ --pipeline_config_path ./object_detection_tools/config/ssd_inception_v2_coco.config \\ --output_directory ./object_detection_tools/exported_graphs/cat_01 \\ --trained_checkpoint_prefix ./object_detection_tools/saved_model/cat_01/model.ckpt-5555 cp ./object_detection_tools/scripts/convert_pbtxt_label.py . python3 ./convert_pbtxt_label.py \\ -l = './object_detection_tools/data/tf_label_map.pbtxt' \\ > ./object_detection_tools/exported_graphs/cat_01/labels.txt \u63a8\u8ad6\u306e\u5b9f\u884c \u00b6 \u30b3\u30f3\u30c6\u30ca\u5185\u3002 cd ~/models/research/object_detection_tools python3 scripts/detect.py -i ./test.jpg","title":"Tutorial"},{"location":"Tutorial-TensorFlow-Models/#tutorial","text":"Inception v2 base SSD 300 \u306e\u8ee2\u79fb\u5b66\u7fd2 (Transfer Learning) tensorflow/models: Models and examples built with TensorFlow Tensorflow Object Detection API v1.13.0 Installation - Tensorflow Object Detection API v1.13.0 model zoo - Tensorflow Object Detection API v1.13.0","title":"Tutorial"},{"location":"Tutorial-TensorFlow-Models/#prepare_dataset","text":"","title":"Prepare dataset"},{"location":"Tutorial-TensorFlow-Models/#train_val","text":".tfrecord \u3092\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u914d\u7f6e\u3002 data/train : \u6559\u5e2b\u30c7\u30fc\u30bf data/val : \u691c\u8a3c\u30c7\u30fc\u30bf $ tree data data \u251c\u2500\u2500 change_tfrecord_filename.sh \u251c\u2500\u2500 cat-TFRecords-export \u251c\u2500\u2500 tf_label_map.pbtxt \u251c\u2500\u2500 train \u2502 \u251c\u2500\u2500 frame-fa9aee7507d749368eaea01fde15dc0f.tfrecord \u2502 \u251c\u2500\u2500 frame-fb52802ac5fb1d0e4465c535603cc8d1.tfrecord \u2502 \u251c\u2500\u2500 frame-fcca1acaa65736d0632a4c9d09f46f34.tfrecord ... \u2502 \u2514\u2500\u2500 frame-fe032dbfda72e3a42d0a9b00b62695fe.tfrecord \u2514\u2500\u2500 val \u251c\u2500\u2500 frame-fe8158671dbeda266efea62af20d7e97.tfrecord \u251c\u2500\u2500 frame-ffef9a9882b57f2c6124c889a3ec9afd.tfrecord \u251c\u2500\u2500 frame-ffef9a9882b57f2c6124c889a3ec9afd.tfrecord ... cat-TFRecords-export \u306b\u3059\u3079\u3066\u306e tfrecord \u304c\u5165\u3063\u3066\u3044\u308b\u3082\u306e\u3068\u3057\u3066\u3001 cd docs/Tutorial-TensorFlow-Models/data bash ./change_tfrecord_filename.sh cat-TFRecords-export \u3042\u3068\u306f train \u3068 val \u306b tfrecord \u3092\u5206\u3051\u3066\u914d\u7f6e\u3059\u308b\u3002","title":"train val"},{"location":"Tutorial-TensorFlow-Models/#tf_label_mappbtxt","text":"item { id: 1 name: 'cat' }","title":"tf_label_map.pbtxt"},{"location":"Tutorial-TensorFlow-Models/#config","text":"config/ssd_inception_v2_coco.config \u3092\u7de8\u96c6\u3059\u308b\u3053\u3068\u3067\u524d\u51e6\u7406 (data augmentation) \u3092\u8ffd\u52a0\u30fb\u524a\u9664\u3067\u304d\u308b\u3002 \u305d\u306e\u4ed6 batch size, learning rate \u306a\u3069\u306e\u8a2d\u5b9a\u3082\u3053\u3053\u3067\u6307\u5b9a\u3067\u304d\u308b\u3002","title":"config"},{"location":"Tutorial-TensorFlow-Models/#build_docker_image","text":"cd docs/Tutorial-TensorFlow-Models # Build make build","title":"Build Docker image"},{"location":"Tutorial-TensorFlow-Models/#run_container","text":"make run \u30b3\u30f3\u30c6\u30ca\u306b\u30ed\u30b0\u30a4\u30f3\u3057\u305f\u3089\u4ee5\u4e0b\u3092\u6bce\u56de\u5b9f\u884c\u3059\u308b\u3002 cd ~/models/research export PYTHONPATH = ${ PYTHONPATH } : $( pwd ) : $( pwd ) /slim \u52d5\u4f5c\u30c6\u30b9\u30c8 cd ~/models/research python3 ./object_detection/builders/model_builder_test.py","title":"Run Container"},{"location":"Tutorial-TensorFlow-Models/#train","text":"\u30db\u30b9\u30c8\u30de\u30b7\u30f3\u3067\u516c\u958b\u3055\u308c\u3066\u3044\u308b\u4e8b\u524d\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3002 cd models bash get_ssd_inception_v2_coco_model.sh \u30b3\u30f3\u30c6\u30ca\u5185\u3002 nohup python3 ./object_detection/model_main.py \\ --pipeline_config_path = \"./object_detection_tools/config/ssd_inception_v2_coco.config\" \\ --model_dir = \"./object_detection_tools/saved_model/cat_01\" \\ --num_train_steps = 20000 \\ --alsologtostderr > ./object_detection_tools/nohup.log & ctrl+p+q \u3067\u30b3\u30f3\u30c6\u30ca\u304b\u3089\u629c\u3051\u308b\u3002","title":"Train"},{"location":"Tutorial-TensorFlow-Models/#tensorboard","text":"cd docs/Tutorial-TensorFlow-Models/tensorboard docker build . -t tensorboard:latest docker run --rm -it -v ${ PWD } /saved_model/cat_01:/logs -p 6006 :6006 --network host --name tensorboard tensorboard:latest","title":"Tensorboard"},{"location":"Tutorial-TensorFlow-Models/#_1","text":"\u30b3\u30f3\u30c6\u30ca\u5185\u3002 python3 ./object_detection/export_inference_graph.py \\ --input_type image_tensor \\ --pipeline_config_path ./object_detection_tools/config/ssd_inception_v2_coco.config \\ --output_directory ./object_detection_tools/exported_graphs/cat_01 \\ --trained_checkpoint_prefix ./object_detection_tools/saved_model/cat_01/model.ckpt-5555 cp ./object_detection_tools/scripts/convert_pbtxt_label.py . python3 ./convert_pbtxt_label.py \\ -l = './object_detection_tools/data/tf_label_map.pbtxt' \\ > ./object_detection_tools/exported_graphs/cat_01/labels.txt","title":"\u30e2\u30c7\u30eb\u5909\u63db"},{"location":"Tutorial-TensorFlow-Models/#_2","text":"\u30b3\u30f3\u30c6\u30ca\u5185\u3002 cd ~/models/research/object_detection_tools python3 scripts/detect.py -i ./test.jpg","title":"\u63a8\u8ad6\u306e\u5b9f\u884c"},{"location":"Tutorial-VoTT/","text":"VoTT Tutorial \u00b6 Tutorial for annotation with VoTT v2.2.0 microsoft/VoTT - GitHub Visual Object Tagging Tool: An electron app for building end to end Object Detection Models from Images and Videos. Download VoTT \u00b6 Go to releases page and check the latest version. Install to macOS \u00b6 export VOTT_VERSION = \"2.2.0\" wget \"https://github.com/microsoft/VoTT/releases/download/v ${ VOTT_VERSION } /vott- ${ VOTT_VERSION } -darwin.dmg\" hdiutil mount \"vott- ${ VOTT_VERSION } -darwin.dmg\" cp -r \"/Volumes/vott ${ VOTT_VERSION } /vott.app\" /Applications/ hdiutil detach \"/Volumes/vott ${ VOTT_VERSION } \" open -a vott.app Install to Linux \u00b6 export VOTT_VERSION = \"2.2.0\" wget \"https://github.com/microsoft/VoTT/releases/download/v ${ VOTT_VERSION } /vott- ${ VOTT_VERSION } -linux.snap\" sudo snap install --dangerous \"./vott- ${ VOTT_VERSION } -linux.snap\" Install to Windows \u00b6 TBW. Setup a new project \u00b6 You can use sample_project for your tutorial. The following is a project structure. Put your images in a source directory. sample_project \u251c\u2500\u2500 source \u2502 \u251c\u2500\u2500 car_1.jpg \u2502 \u251c\u2500\u2500 car_2.jpg \u2502 \u2514\u2500\u2500 car_3.jpg \u2514\u2500\u2500 target Open VoTT app Click New Project Fill Display Name Source Connection \u00b6 Click Add Connection Fill Display Name Provider Select Local File System Select your source folder Click Save Connection Set the connection to Source Connection Target Connection \u00b6 Click Add Connection Fill Display Name Provider Select Local File System Select your target folder Click Save Connection Set the connection to Target Connection Finally, click Save Project Annotation \u00b6 You can also view the video that shows a manner of annotation (sample.mp4) . Keyboard Shortcuts \u00b6 Shortcut key Command W or ArrowUp Previous Asset S or ArrowDown Next Asset Ctrl + Arrowkey Move Region Ctrl + Alt + Arrowkey Shrink Region Ctrl + Shift + Arrowkey Expand Region Mouse Controls \u00b6 Mode Command Two-point mode Hold down Ctrl while creating a region Square mode Hold down Shift while creating a region Multi-select mode Hold down Shift while selecting regions Exclusive Tracking mode Ctrl + N to block frame UI allowing a user to create a region on top of existing regions Tag ordering \u00b6 Hotkeys of 1 through 0 are assigned to the first ten tags. These can be reordered by using the up/down arrow icons in in the tag editor pane. Tag locking \u00b6 A tag can be locked for repeated tagging using the lock icon at the top of the tag editor pane. Tags can also be locked by combining Ctrl or Cmd and the tag hotkey, i.e. Ctrl + 2 would lock the second tag in the list. Check your progress \u00b6 Export dataset \u00b6 Go to Export Settings and set your exporting format. Click Save Export Settings . Click Export button on the tags editor. The following is a project structure after exporting. sample_project \u251c\u2500\u2500 source \u2502 \u251c\u2500\u2500 car_1.jpg \u2502 \u251c\u2500\u2500 car_2.jpg \u2502 \u2514\u2500\u2500 car_3.jpg \u2514\u2500\u2500 target \u251c\u2500\u2500 32db62ab992c250ba2312fdc3babc444-asset.json \u251c\u2500\u2500 41e0a9f85a8d20040692c8390317d3ce-asset.json \u251c\u2500\u2500 7ce54d9571515f858d958f3a20cd3ff7-asset.json \u251c\u2500\u2500 sample_project-TFRecords-export \u2502 \u251c\u2500\u2500 car_1.tfrecord \u2502 \u251c\u2500\u2500 car_2.tfrecord \u2502 \u251c\u2500\u2500 car_3.tfrecord \u2502 \u2514\u2500\u2500 tf_label_map.pbtxt \u2514\u2500\u2500 sample_project.vott Open existing project \u00b6 You can use sample_existing_project as an example for opening local project. Click Open Local Project Select VoTT project file (e.g. sample_project.vott )","title":"VoTT Tutorial"},{"location":"Tutorial-VoTT/#vott_tutorial","text":"Tutorial for annotation with VoTT v2.2.0 microsoft/VoTT - GitHub Visual Object Tagging Tool: An electron app for building end to end Object Detection Models from Images and Videos.","title":"VoTT Tutorial"},{"location":"Tutorial-VoTT/#download_vott","text":"Go to releases page and check the latest version.","title":"Download VoTT"},{"location":"Tutorial-VoTT/#install_to_macos","text":"export VOTT_VERSION = \"2.2.0\" wget \"https://github.com/microsoft/VoTT/releases/download/v ${ VOTT_VERSION } /vott- ${ VOTT_VERSION } -darwin.dmg\" hdiutil mount \"vott- ${ VOTT_VERSION } -darwin.dmg\" cp -r \"/Volumes/vott ${ VOTT_VERSION } /vott.app\" /Applications/ hdiutil detach \"/Volumes/vott ${ VOTT_VERSION } \" open -a vott.app","title":"Install to macOS"},{"location":"Tutorial-VoTT/#install_to_linux","text":"export VOTT_VERSION = \"2.2.0\" wget \"https://github.com/microsoft/VoTT/releases/download/v ${ VOTT_VERSION } /vott- ${ VOTT_VERSION } -linux.snap\" sudo snap install --dangerous \"./vott- ${ VOTT_VERSION } -linux.snap\"","title":"Install to Linux"},{"location":"Tutorial-VoTT/#install_to_windows","text":"TBW.","title":"Install to Windows"},{"location":"Tutorial-VoTT/#setup_a_new_project","text":"You can use sample_project for your tutorial. The following is a project structure. Put your images in a source directory. sample_project \u251c\u2500\u2500 source \u2502 \u251c\u2500\u2500 car_1.jpg \u2502 \u251c\u2500\u2500 car_2.jpg \u2502 \u2514\u2500\u2500 car_3.jpg \u2514\u2500\u2500 target Open VoTT app Click New Project Fill Display Name","title":"Setup a new project"},{"location":"Tutorial-VoTT/#source_connection","text":"Click Add Connection Fill Display Name Provider Select Local File System Select your source folder Click Save Connection Set the connection to Source Connection","title":"Source Connection"},{"location":"Tutorial-VoTT/#target_connection","text":"Click Add Connection Fill Display Name Provider Select Local File System Select your target folder Click Save Connection Set the connection to Target Connection Finally, click Save Project","title":"Target Connection"},{"location":"Tutorial-VoTT/#annotation","text":"You can also view the video that shows a manner of annotation (sample.mp4) .","title":"Annotation"},{"location":"Tutorial-VoTT/#keyboard_shortcuts","text":"Shortcut key Command W or ArrowUp Previous Asset S or ArrowDown Next Asset Ctrl + Arrowkey Move Region Ctrl + Alt + Arrowkey Shrink Region Ctrl + Shift + Arrowkey Expand Region","title":"Keyboard Shortcuts"},{"location":"Tutorial-VoTT/#mouse_controls","text":"Mode Command Two-point mode Hold down Ctrl while creating a region Square mode Hold down Shift while creating a region Multi-select mode Hold down Shift while selecting regions Exclusive Tracking mode Ctrl + N to block frame UI allowing a user to create a region on top of existing regions","title":"Mouse Controls"},{"location":"Tutorial-VoTT/#tag_ordering","text":"Hotkeys of 1 through 0 are assigned to the first ten tags. These can be reordered by using the up/down arrow icons in in the tag editor pane.","title":"Tag ordering"},{"location":"Tutorial-VoTT/#tag_locking","text":"A tag can be locked for repeated tagging using the lock icon at the top of the tag editor pane. Tags can also be locked by combining Ctrl or Cmd and the tag hotkey, i.e. Ctrl + 2 would lock the second tag in the list.","title":"Tag locking"},{"location":"Tutorial-VoTT/#check_your_progress","text":"","title":"Check your progress"},{"location":"Tutorial-VoTT/#export_dataset","text":"Go to Export Settings and set your exporting format. Click Save Export Settings . Click Export button on the tags editor. The following is a project structure after exporting. sample_project \u251c\u2500\u2500 source \u2502 \u251c\u2500\u2500 car_1.jpg \u2502 \u251c\u2500\u2500 car_2.jpg \u2502 \u2514\u2500\u2500 car_3.jpg \u2514\u2500\u2500 target \u251c\u2500\u2500 32db62ab992c250ba2312fdc3babc444-asset.json \u251c\u2500\u2500 41e0a9f85a8d20040692c8390317d3ce-asset.json \u251c\u2500\u2500 7ce54d9571515f858d958f3a20cd3ff7-asset.json \u251c\u2500\u2500 sample_project-TFRecords-export \u2502 \u251c\u2500\u2500 car_1.tfrecord \u2502 \u251c\u2500\u2500 car_2.tfrecord \u2502 \u251c\u2500\u2500 car_3.tfrecord \u2502 \u2514\u2500\u2500 tf_label_map.pbtxt \u2514\u2500\u2500 sample_project.vott","title":"Export dataset"},{"location":"Tutorial-VoTT/#open_existing_project","text":"You can use sample_existing_project as an example for opening local project. Click Open Local Project Select VoTT project file (e.g. sample_project.vott )","title":"Open existing project"},{"location":"Tutorial-YOLO-Darknet/","text":"Darknet YOLO v3 and v4 \u00b6 v4 Paper: [2004.10934] YOLOv4: Optimal Speed and Accuracy of Object Detection Repository: AlexeyAB/darknet: YOLOv4 - Neural Networks for Object Detection (Windows and Linux version of Darknet ) Google Colab: YOLOv4_Tutorial.ipynb - Colaboratory Build Docker Image \u00b6 cd ./docs/Tutorial-YOLO-Darknet Edit Makefile \u00b6 \u5229\u7528\u3059\u308b GPU \u3054\u3068\u306b Makefile \u3092\u7de8\u96c6\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002 GeForce RTX 2080 Ti \u3067\u3042\u308c\u3070\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3059\u308b\u3002(\u30c7\u30d5\u30a9\u30eb\u30c8) # GeForce RTX 2080 Ti, RTX 2080, RTX 2070, Quadro RTX 8000, Quadro RTX 6000, Quadro RTX 5000, Tesla T4, XNOR Tensor Cores ARCH = -gencode arch = compute_75,code =[ sm_75,compute_75 ] # GTX 1080, GTX 1070, GTX 1060, GTX 1050, GTX 1030, Titan Xp, Tesla P40, Tesla P4 # ARCH= -gencode arch=compute_61,code=sm_61 -gencode arch=compute_61,code=compute_61 GTX 1080 \u3067\u3042\u308c\u3070\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3059\u308b\u3002 # GeForce RTX 2080 Ti, RTX 2080, RTX 2070, Quadro RTX 8000, Quadro RTX 6000, Quadro RTX 5000, Tesla T4, XNOR Tensor Cores # ARCH= -gencode arch=compute_75,code=[sm_75,compute_75] # GTX 1080, GTX 1070, GTX 1060, GTX 1050, GTX 1030, Titan Xp, Tesla P40, Tesla P4 ARCH = -gencode arch = compute_61,code = sm_61 -gencode arch = compute_61,code = compute_61 Build \u00b6 $ nvidia-smi NVIDIA-SMI 440.82 Driver Version: 440.82 CUDA Version: 10.2 nvidia-smi \u3067\u78ba\u8a8d\u3067\u304d\u308b CUDA Version \u3068 Base Docker image nvidia/cuda \u306e tag \u3092\u4e00\u81f4\u3055\u305b\u308b\u3002 docker build . -t darknet-yolo:latest --build-arg BASE_IMAGE = \"nvidia/cuda:10.2-cudnn7-devel-ubuntu18.04\" Run Container \u00b6 docker run --rm -i -t --gpus all darknet-yolo:latest bash Predict \u00b6 \u63a8\u8ad6\u306e\u5b9f\u884c\u4f8b\u3092\u4ee5\u4e0b\u306b\u793a\u3059\u3002 $ ./darknet detector test cfg/coco.data cfg/yolov3.cfg yolov3.weights data/dog.jpg ... data/dog.jpg: Predicted in 12.776000 milli-seconds. bicycle: 99% dog: 100% truck: 94% ... $ ./darknet detector test cfg/coco.data cfg/yolov4.cfg yolov4.weights data/dog.jpg ... data/dog.jpg: Predicted in 24.482000 milli-seconds. bicycle: 92% dog: 98% truck: 92% pottedplant: 33% ... $ python3 darknet.py ... Total BFLOPS 128.459 avg_outputs = 1068395 Allocate additional workspace_size = 52.43 MB Try to load weights: yolov4.weights Loading weights from yolov4.weights... seen 64, trained: 32032 K-images (500 Kilo-batches_64) Done! Loaded 162 layers from weights-file Loaded - names_list: data/coco.names, classes = 80 Unable to show image: No module named 'skimage' [('dog', 0.9787506461143494, (220.98822021484375, 383.2079772949219, 184.41787719726562, 316.5090637207031)), ('bicycle', 0.921798586845398, (343.4819641113281, 276.87603759765625, 458.0648193359375, 298.7120361328125)), ('truck', 0.91830974817276, (574.2606201171875, 123.24830627441406, 220.67361450195312, 93.20550537109375)), ('pottedplant', 0.33072134852409363, (699.3265380859375, 131.88845825195312, 36.533931732177734, 45.44673538208008))] v3 v4","title":"Darknet YOLO v3 and v4"},{"location":"Tutorial-YOLO-Darknet/#darknet_yolo_v3_and_v4","text":"v4 Paper: [2004.10934] YOLOv4: Optimal Speed and Accuracy of Object Detection Repository: AlexeyAB/darknet: YOLOv4 - Neural Networks for Object Detection (Windows and Linux version of Darknet ) Google Colab: YOLOv4_Tutorial.ipynb - Colaboratory","title":"Darknet YOLO v3 and v4"},{"location":"Tutorial-YOLO-Darknet/#build_docker_image","text":"cd ./docs/Tutorial-YOLO-Darknet","title":"Build Docker Image"},{"location":"Tutorial-YOLO-Darknet/#edit_makefile","text":"\u5229\u7528\u3059\u308b GPU \u3054\u3068\u306b Makefile \u3092\u7de8\u96c6\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002 GeForce RTX 2080 Ti \u3067\u3042\u308c\u3070\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3059\u308b\u3002(\u30c7\u30d5\u30a9\u30eb\u30c8) # GeForce RTX 2080 Ti, RTX 2080, RTX 2070, Quadro RTX 8000, Quadro RTX 6000, Quadro RTX 5000, Tesla T4, XNOR Tensor Cores ARCH = -gencode arch = compute_75,code =[ sm_75,compute_75 ] # GTX 1080, GTX 1070, GTX 1060, GTX 1050, GTX 1030, Titan Xp, Tesla P40, Tesla P4 # ARCH= -gencode arch=compute_61,code=sm_61 -gencode arch=compute_61,code=compute_61 GTX 1080 \u3067\u3042\u308c\u3070\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3059\u308b\u3002 # GeForce RTX 2080 Ti, RTX 2080, RTX 2070, Quadro RTX 8000, Quadro RTX 6000, Quadro RTX 5000, Tesla T4, XNOR Tensor Cores # ARCH= -gencode arch=compute_75,code=[sm_75,compute_75] # GTX 1080, GTX 1070, GTX 1060, GTX 1050, GTX 1030, Titan Xp, Tesla P40, Tesla P4 ARCH = -gencode arch = compute_61,code = sm_61 -gencode arch = compute_61,code = compute_61","title":"Edit Makefile"},{"location":"Tutorial-YOLO-Darknet/#build","text":"$ nvidia-smi NVIDIA-SMI 440.82 Driver Version: 440.82 CUDA Version: 10.2 nvidia-smi \u3067\u78ba\u8a8d\u3067\u304d\u308b CUDA Version \u3068 Base Docker image nvidia/cuda \u306e tag \u3092\u4e00\u81f4\u3055\u305b\u308b\u3002 docker build . -t darknet-yolo:latest --build-arg BASE_IMAGE = \"nvidia/cuda:10.2-cudnn7-devel-ubuntu18.04\"","title":"Build"},{"location":"Tutorial-YOLO-Darknet/#run_container","text":"docker run --rm -i -t --gpus all darknet-yolo:latest bash","title":"Run Container"},{"location":"Tutorial-YOLO-Darknet/#predict","text":"\u63a8\u8ad6\u306e\u5b9f\u884c\u4f8b\u3092\u4ee5\u4e0b\u306b\u793a\u3059\u3002 $ ./darknet detector test cfg/coco.data cfg/yolov3.cfg yolov3.weights data/dog.jpg ... data/dog.jpg: Predicted in 12.776000 milli-seconds. bicycle: 99% dog: 100% truck: 94% ... $ ./darknet detector test cfg/coco.data cfg/yolov4.cfg yolov4.weights data/dog.jpg ... data/dog.jpg: Predicted in 24.482000 milli-seconds. bicycle: 92% dog: 98% truck: 92% pottedplant: 33% ... $ python3 darknet.py ... Total BFLOPS 128.459 avg_outputs = 1068395 Allocate additional workspace_size = 52.43 MB Try to load weights: yolov4.weights Loading weights from yolov4.weights... seen 64, trained: 32032 K-images (500 Kilo-batches_64) Done! Loaded 162 layers from weights-file Loaded - names_list: data/coco.names, classes = 80 Unable to show image: No module named 'skimage' [('dog', 0.9787506461143494, (220.98822021484375, 383.2079772949219, 184.41787719726562, 316.5090637207031)), ('bicycle', 0.921798586845398, (343.4819641113281, 276.87603759765625, 458.0648193359375, 298.7120361328125)), ('truck', 0.91830974817276, (574.2606201171875, 123.24830627441406, 220.67361450195312, 93.20550537109375)), ('pottedplant', 0.33072134852409363, (699.3265380859375, 131.88845825195312, 36.533931732177734, 45.44673538208008))] v3 v4","title":"Predict"},{"location":"setup/","text":"\u74b0\u5883\u69cb\u7bc9 \u00b6 \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7 \u00b6 Ubuntu 18.04 \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb NVIDIA Driver \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u30fb\u66f4\u65b0 Docker, Docker Compose, nvidia-docker \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","title":"\u74b0\u5883\u69cb\u7bc9"},{"location":"setup/#_1","text":"","title":"\u74b0\u5883\u69cb\u7bc9"},{"location":"setup/#_2","text":"Ubuntu 18.04 \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb NVIDIA Driver \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u30fb\u66f4\u65b0 Docker, Docker Compose, nvidia-docker \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","title":"\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7"},{"location":"setup/1-ubuntu/","text":"1. Ubuntu \u00b6 Create Boot USB Disk \u00b6 balenaEtcher - Flash OS images to SD cards & USB drives balenaEtcher \u304c\u4fbf\u5229\u3002 Install Ubuntu \u00b6 Install Ubuntu desktop | Ubuntu Upgrade dependencies \u00b6 \u5b9a\u671f\u7684\u306b\u4ee5\u4e0b\u3092\u5b9f\u884c\u3057\u3066\u3001\u30c4\u30fc\u30eb\u7b49\u3092\u6700\u65b0\u7248\u306b\u66f4\u65b0\u3057\u305f\u65b9\u304c\u3088\u3044\u3002 # \u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u4e00\u89a7\u306e\u66f4\u65b0 sudo apt update # \u66f4\u65b0\u53ef\u80fd\u306a\u4f9d\u5b58\u306e\u4e00\u89a7\u3092\u8868\u793a apt list --upgradable # \u66f4\u65b0\u53ef\u80fd\u306a\u4f9d\u5b58\u3092\u66f4\u65b0 sudo apt upgrade -y","title":"1. Ubuntu"},{"location":"setup/1-ubuntu/#1_ubuntu","text":"","title":"1. Ubuntu"},{"location":"setup/1-ubuntu/#create_boot_usb_disk","text":"balenaEtcher - Flash OS images to SD cards & USB drives balenaEtcher \u304c\u4fbf\u5229\u3002","title":"Create Boot USB Disk"},{"location":"setup/1-ubuntu/#install_ubuntu","text":"Install Ubuntu desktop | Ubuntu","title":"Install Ubuntu"},{"location":"setup/1-ubuntu/#upgrade_dependencies","text":"\u5b9a\u671f\u7684\u306b\u4ee5\u4e0b\u3092\u5b9f\u884c\u3057\u3066\u3001\u30c4\u30fc\u30eb\u7b49\u3092\u6700\u65b0\u7248\u306b\u66f4\u65b0\u3057\u305f\u65b9\u304c\u3088\u3044\u3002 # \u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u4e00\u89a7\u306e\u66f4\u65b0 sudo apt update # \u66f4\u65b0\u53ef\u80fd\u306a\u4f9d\u5b58\u306e\u4e00\u89a7\u3092\u8868\u793a apt list --upgradable # \u66f4\u65b0\u53ef\u80fd\u306a\u4f9d\u5b58\u3092\u66f4\u65b0 sudo apt upgrade -y","title":"Upgrade dependencies"},{"location":"setup/2-nvidia-driver/","text":"2. NVIDIA Driver \u00b6 To Docker user Docker container \u304b\u3089 GPU \u3092\u5229\u7528\u3059\u308b\u5834\u5408\u306f CUDA \u3084 cuDNN \u3092\u30db\u30b9\u30c8\u30de\u30b7\u30f3\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u5fc5\u8981\u306f\u306a\u3044\u306e\u3067\u3001 CUDA \u306e\u90e8\u5206\u306f\u95a2\u4fc2\u306a\u3044\u3002 \u6ce8\u610f ctrl-c \u306a\u3069\u3067\u4f5c\u696d\u3092\u4e2d\u65ad\u3057\u306a\u3044\u3088\u3046\u306b\u6c17\u3092\u3064\u3051\u308b\u3053\u3068\u3002 Installation \u00b6 NVIDIA Driver \u00b6 sudo add-apt-repository ppa:graphics-drivers/ppa sudo apt update ubuntu-drivers devices $ ubuntu-drivers devices == /sys/devices/pci0000:16/0000:16:00.0/0000:17:00.0 == modalias : pci:v000010DEd00001E07sv00001043sd00008666bc03sc00i00 vendor : NVIDIA Corporation driver : nvidia-driver-435 - distro non-free driver : nvidia-driver-440 - third-party free recommended driver : nvidia-driver-415 - third-party free driver : nvidia-driver-410 - third-party free driver : xserver-xorg-video-nouveau - distro free builtin recommended \u306e\u3082\u306e\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002 sudo apt install -y nvidia-driver-440 sudo reboot \u518d\u8d77\u52d5\u5f8c\u306b nvidia-smi \u3067 GPU status \u3092\u53d6\u5f97\u3067\u304d\u308c\u3070\u6210\u529f\u3002 $ nvidia-smi Sat Jun 6 13:22:56 2020 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 440.82 Driver Version: 440.82 CUDA Version: 10.2 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 GeForce RTX 208... Off | 00000000:17:00.0 Off | N/A | | 24% 35C P8 14W / 250W | 119MiB / 11018MiB | 0% Default | +-------------------------------+----------------------+----------------------+ ... CUDA cuDNN \u00b6 conda \u3082\u3057\u304f\u306f nvidia-docker \u3092\u5229\u7528\u3059\u308b\u5834\u5408\u306f CUDA \u3084 cuDNN \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306f\u4e0d\u8981\u3002 Upgrade \u00b6 \u53e4\u3044\u30c9\u30e9\u30a4\u30d0\u30fc\u3068 cuda \u3092\u524a\u9664 \u00b6 sudo apt --purge remove 'nvidia-*' sudo apt --purge remove 'cuda-*' dpkg -l | grep nvidia dpkg -l | grep cuda \u3067\u6b8b\u308a\u304c\u306a\u3044\u304b\u3092\u78ba\u8a8d\u3002 \u3082\u3057 cuda \u3067\u6b8b\u308a\u304c\u3042\u3063\u305f\u3089 autoremove \u3067\u524a\u9664\u3092\u8a66\u307f\u308b\u3002 sudo apt autoremove cuda \u3053\u308c\u3067\u3082\u307e\u3060\u6d88\u3048\u306a\u3044\u5834\u5408\u306b\u306f\u500b\u5225\u306b remove \u3059\u308b\u3002 \u65b0\u3057\u3044\u30c9\u30e9\u30a4\u30d0\u30fc\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb \u00b6 \u30ea\u30dd\u30b8\u30c8\u30ea\u3092\u8ffd\u52a0\u3057\u3066\u3001\u30d1\u30c3\u30b1\u30fc\u30b8\u4e00\u89a7\u3092\u30a2\u30c3\u30d7\u30c7\u30fc\u30c8\u3057\u305f\u5f8c\u306b\u3001\u63a8\u5968\u30c9\u30e9\u30a4\u30d0\u30fc\u3092\u78ba\u8a8d\u3059\u308b\u3002 sudo add-apt-repository ppa:graphics-drivers/ppa sudo apt update ubuntu-drivers devices \u3092\u5b9f\u884c\u3059\u308b\u3068 == /sys/devices/pci0000:16/0000:16:00.0/0000:17:00.0 == modalias : pci:v000010DEd00001E07sv00001043sd00008666bc03sc00i00 vendor : NVIDIA Corporation driver : nvidia-driver-415 - third-party free driver : nvidia-driver-435 - distro non-free driver : nvidia-driver-410 - third-party free driver : nvidia-driver-440 - distro non-free recommended driver : xserver-xorg-video-nouveau - distro free builtin \u306a\u3069(\u4e00\u90e8\u7701\u7565)\u304c\u51fa\u529b\u3055\u308c\u308b\u306e\u3067\u3001\u63a8\u5968 (recommended) \u3055\u308c\u305f\u30c9\u30e9\u30a4\u30d0\u30fc\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002 sudo apt install -y nvidia-driver-440 \u518d\u8d77\u52d5\u3057\u305f\u5f8c\u306b GPU \u304c\u8a8d\u8b58\u3067\u304d\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002 sudo reboot nvidia-smi \u3053\u3053\u307e\u3067\u3067\u304d\u305f\u3089\u52dd\u3061\u3002","title":"2. NVIDIA Driver"},{"location":"setup/2-nvidia-driver/#2_nvidia_driver","text":"To Docker user Docker container \u304b\u3089 GPU \u3092\u5229\u7528\u3059\u308b\u5834\u5408\u306f CUDA \u3084 cuDNN \u3092\u30db\u30b9\u30c8\u30de\u30b7\u30f3\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u5fc5\u8981\u306f\u306a\u3044\u306e\u3067\u3001 CUDA \u306e\u90e8\u5206\u306f\u95a2\u4fc2\u306a\u3044\u3002 \u6ce8\u610f ctrl-c \u306a\u3069\u3067\u4f5c\u696d\u3092\u4e2d\u65ad\u3057\u306a\u3044\u3088\u3046\u306b\u6c17\u3092\u3064\u3051\u308b\u3053\u3068\u3002","title":"2. NVIDIA Driver"},{"location":"setup/2-nvidia-driver/#installation","text":"","title":"Installation"},{"location":"setup/2-nvidia-driver/#nvidia_driver","text":"sudo add-apt-repository ppa:graphics-drivers/ppa sudo apt update ubuntu-drivers devices $ ubuntu-drivers devices == /sys/devices/pci0000:16/0000:16:00.0/0000:17:00.0 == modalias : pci:v000010DEd00001E07sv00001043sd00008666bc03sc00i00 vendor : NVIDIA Corporation driver : nvidia-driver-435 - distro non-free driver : nvidia-driver-440 - third-party free recommended driver : nvidia-driver-415 - third-party free driver : nvidia-driver-410 - third-party free driver : xserver-xorg-video-nouveau - distro free builtin recommended \u306e\u3082\u306e\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002 sudo apt install -y nvidia-driver-440 sudo reboot \u518d\u8d77\u52d5\u5f8c\u306b nvidia-smi \u3067 GPU status \u3092\u53d6\u5f97\u3067\u304d\u308c\u3070\u6210\u529f\u3002 $ nvidia-smi Sat Jun 6 13:22:56 2020 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 440.82 Driver Version: 440.82 CUDA Version: 10.2 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 GeForce RTX 208... Off | 00000000:17:00.0 Off | N/A | | 24% 35C P8 14W / 250W | 119MiB / 11018MiB | 0% Default | +-------------------------------+----------------------+----------------------+ ...","title":"NVIDIA Driver"},{"location":"setup/2-nvidia-driver/#cuda_cudnn","text":"conda \u3082\u3057\u304f\u306f nvidia-docker \u3092\u5229\u7528\u3059\u308b\u5834\u5408\u306f CUDA \u3084 cuDNN \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306f\u4e0d\u8981\u3002","title":"CUDA cuDNN"},{"location":"setup/2-nvidia-driver/#upgrade","text":"","title":"Upgrade"},{"location":"setup/2-nvidia-driver/#cuda","text":"sudo apt --purge remove 'nvidia-*' sudo apt --purge remove 'cuda-*' dpkg -l | grep nvidia dpkg -l | grep cuda \u3067\u6b8b\u308a\u304c\u306a\u3044\u304b\u3092\u78ba\u8a8d\u3002 \u3082\u3057 cuda \u3067\u6b8b\u308a\u304c\u3042\u3063\u305f\u3089 autoremove \u3067\u524a\u9664\u3092\u8a66\u307f\u308b\u3002 sudo apt autoremove cuda \u3053\u308c\u3067\u3082\u307e\u3060\u6d88\u3048\u306a\u3044\u5834\u5408\u306b\u306f\u500b\u5225\u306b remove \u3059\u308b\u3002","title":"\u53e4\u3044\u30c9\u30e9\u30a4\u30d0\u30fc\u3068 cuda \u3092\u524a\u9664"},{"location":"setup/2-nvidia-driver/#_1","text":"\u30ea\u30dd\u30b8\u30c8\u30ea\u3092\u8ffd\u52a0\u3057\u3066\u3001\u30d1\u30c3\u30b1\u30fc\u30b8\u4e00\u89a7\u3092\u30a2\u30c3\u30d7\u30c7\u30fc\u30c8\u3057\u305f\u5f8c\u306b\u3001\u63a8\u5968\u30c9\u30e9\u30a4\u30d0\u30fc\u3092\u78ba\u8a8d\u3059\u308b\u3002 sudo add-apt-repository ppa:graphics-drivers/ppa sudo apt update ubuntu-drivers devices \u3092\u5b9f\u884c\u3059\u308b\u3068 == /sys/devices/pci0000:16/0000:16:00.0/0000:17:00.0 == modalias : pci:v000010DEd00001E07sv00001043sd00008666bc03sc00i00 vendor : NVIDIA Corporation driver : nvidia-driver-415 - third-party free driver : nvidia-driver-435 - distro non-free driver : nvidia-driver-410 - third-party free driver : nvidia-driver-440 - distro non-free recommended driver : xserver-xorg-video-nouveau - distro free builtin \u306a\u3069(\u4e00\u90e8\u7701\u7565)\u304c\u51fa\u529b\u3055\u308c\u308b\u306e\u3067\u3001\u63a8\u5968 (recommended) \u3055\u308c\u305f\u30c9\u30e9\u30a4\u30d0\u30fc\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002 sudo apt install -y nvidia-driver-440 \u518d\u8d77\u52d5\u3057\u305f\u5f8c\u306b GPU \u304c\u8a8d\u8b58\u3067\u304d\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002 sudo reboot nvidia-smi \u3053\u3053\u307e\u3067\u3067\u304d\u305f\u3089\u52dd\u3061\u3002","title":"\u65b0\u3057\u3044\u30c9\u30e9\u30a4\u30d0\u30fc\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb"},{"location":"setup/3-docker/","text":"3. Docker \u00b6 Install Docker \u00b6 which docker \u3084 which docker-compose \u306a\u3069\u3067\u78ba\u8a8d\u3057\u3001\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u306a\u3051\u308c\u3070\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002 macOS \u00b6 Install Docker Desktop on Mac | Docker Documentation To macOS users macOS \u306e\u5834\u5408 Docker for Mac \u306f docker-compose \u3082\u542b\u3093\u3067\u3044\u308b\u3002 Ubuntu 18.04 \u00b6 \u516c\u5f0f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u5f93\u3063\u3066 Docker \u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3002 Install Docker Engine on Ubuntu | Docker Documentation \u7d9a\u3044\u3066 Docker Compose \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3002 Install Docker Compose | Docker Documentation compose \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306b\u5229\u7528\u3059\u308b\u30c4\u30fc\u30eb\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002 sudo apt install -y curl jq \u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3067 compose \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3068\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u304c\u3067\u304d\u308b\u3002 export DOCKER_COMPOSE_VERSION = $( curl -s https://api.github.com/repos/docker/compose/releases/latest | jq -r '.tag_name' ) sudo curl -L \"https://github.com/docker/compose/releases/download/ ${ DOCKER_COMPOSE_VERSION } /docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose && \\ sudo chmod +x /usr/local/bin/docker-compose && \\ docker-compose --version Install nvidia-docker \u00b6 nvidia-docker \u00b6 NVIDIA/nvidia-docker: Build and run Docker containers leveraging NVIDIA GPUs \u4e00\u5fdc\u5b9f\u884c\u3059\u308b\u30b3\u30de\u30f3\u30c9\u3092\u4e0b\u306b\u66f8\u3044\u3066\u304a\u304f\u304c\u3001\u4e0a\u8a18\u3092\u898b\u3066\u6700\u65b0\u306e\u60c5\u5831\u3092\u78ba\u8a8d\u3059\u308b\u3053\u3068\u3002 distribution = $( . /etc/os-release ; echo $ID$VERSION_ID ) curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - curl -s -L https://nvidia.github.io/nvidia-docker/ $distribution /nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list sudo apt update && sudo apt install -y nvidia-container-toolkit sudo systemctl restart docker Container \u304b\u3089 GPU \u3092\u5229\u7528\u3059\u308b \u00b6 nvidia-smi \u3067\u78ba\u8a8d\u3067\u304d\u308b CUDA version \u3068 docker image tag \u306e CUDA version \u3092\u4e00\u81f4\u3055\u305b\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002 docker run --rm -i -t --gpus all nvidia/cuda:10.2-base-ubuntu18.04 bash \u30b3\u30f3\u30c6\u30ca\u5185\u3067 nvidia-smi \u3092\u5b9f\u884c\u3057\u3066 GPU status \u3092\u78ba\u8a8d\u3067\u304d\u308c\u3070\u554f\u984c\u306a\u3044\u3002 PyTorch \u3067 GPU \u3092\u78ba\u8a8d \u00b6 python3 \u3092\u5b9f\u884c\u3057\u3066\u30a4\u30f3\u30bf\u30e9\u30af\u30c6\u30a3\u30d6\u30e2\u30fc\u30c9\u3067\u78ba\u8a8d\u3059\u308b\u3002 >>> import torch >>> print ( torch . cuda . is_available ()) True >>> torch . cuda . get_device_name ( 0 ) 'GeForce RTX 2080' TensorFlow \u3067 GPU \u3092\u78ba\u8a8d \u00b6 python3 \u3092\u5b9f\u884c\u3057\u3066\u30a4\u30f3\u30bf\u30e9\u30af\u30c6\u30a3\u30d6\u30e2\u30fc\u30c9\u3067\u78ba\u8a8d\u3059\u308b\u3002 from tensorflow.python.client import device_lib print ( device_lib . list_local_devices ()) \u4e0a\u8a18\u3092\u5b9f\u884c\u3059\u308b\u3068\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u5229\u7528\u3067\u304d\u308b\u30c7\u30d0\u30a4\u30b9\u306e\u4e00\u89a7\u3092\u78ba\u8a8d\u3067\u304d\u308b\u3002 2020-06-06 04:53:00.588924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/device:GPU:0 with 10091 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:17:00.0, compute capability: 7.5) 2020-06-06 04:53:00.590217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/device:GPU:1 with 10202 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)","title":"3. Docker"},{"location":"setup/3-docker/#3_docker","text":"","title":"3. Docker"},{"location":"setup/3-docker/#install_docker","text":"which docker \u3084 which docker-compose \u306a\u3069\u3067\u78ba\u8a8d\u3057\u3001\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u306a\u3051\u308c\u3070\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002","title":"Install Docker"},{"location":"setup/3-docker/#macos","text":"Install Docker Desktop on Mac | Docker Documentation To macOS users macOS \u306e\u5834\u5408 Docker for Mac \u306f docker-compose \u3082\u542b\u3093\u3067\u3044\u308b\u3002","title":"macOS"},{"location":"setup/3-docker/#ubuntu_1804","text":"\u516c\u5f0f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u5f93\u3063\u3066 Docker \u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3002 Install Docker Engine on Ubuntu | Docker Documentation \u7d9a\u3044\u3066 Docker Compose \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3002 Install Docker Compose | Docker Documentation compose \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306b\u5229\u7528\u3059\u308b\u30c4\u30fc\u30eb\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002 sudo apt install -y curl jq \u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3067 compose \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3068\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u304c\u3067\u304d\u308b\u3002 export DOCKER_COMPOSE_VERSION = $( curl -s https://api.github.com/repos/docker/compose/releases/latest | jq -r '.tag_name' ) sudo curl -L \"https://github.com/docker/compose/releases/download/ ${ DOCKER_COMPOSE_VERSION } /docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose && \\ sudo chmod +x /usr/local/bin/docker-compose && \\ docker-compose --version","title":"Ubuntu 18.04"},{"location":"setup/3-docker/#install_nvidia-docker","text":"","title":"Install nvidia-docker"},{"location":"setup/3-docker/#nvidia-docker","text":"NVIDIA/nvidia-docker: Build and run Docker containers leveraging NVIDIA GPUs \u4e00\u5fdc\u5b9f\u884c\u3059\u308b\u30b3\u30de\u30f3\u30c9\u3092\u4e0b\u306b\u66f8\u3044\u3066\u304a\u304f\u304c\u3001\u4e0a\u8a18\u3092\u898b\u3066\u6700\u65b0\u306e\u60c5\u5831\u3092\u78ba\u8a8d\u3059\u308b\u3053\u3068\u3002 distribution = $( . /etc/os-release ; echo $ID$VERSION_ID ) curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - curl -s -L https://nvidia.github.io/nvidia-docker/ $distribution /nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list sudo apt update && sudo apt install -y nvidia-container-toolkit sudo systemctl restart docker","title":"nvidia-docker"},{"location":"setup/3-docker/#container_gpu","text":"nvidia-smi \u3067\u78ba\u8a8d\u3067\u304d\u308b CUDA version \u3068 docker image tag \u306e CUDA version \u3092\u4e00\u81f4\u3055\u305b\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002 docker run --rm -i -t --gpus all nvidia/cuda:10.2-base-ubuntu18.04 bash \u30b3\u30f3\u30c6\u30ca\u5185\u3067 nvidia-smi \u3092\u5b9f\u884c\u3057\u3066 GPU status \u3092\u78ba\u8a8d\u3067\u304d\u308c\u3070\u554f\u984c\u306a\u3044\u3002","title":"Container \u304b\u3089 GPU \u3092\u5229\u7528\u3059\u308b"},{"location":"setup/3-docker/#pytorch_gpu","text":"python3 \u3092\u5b9f\u884c\u3057\u3066\u30a4\u30f3\u30bf\u30e9\u30af\u30c6\u30a3\u30d6\u30e2\u30fc\u30c9\u3067\u78ba\u8a8d\u3059\u308b\u3002 >>> import torch >>> print ( torch . cuda . is_available ()) True >>> torch . cuda . get_device_name ( 0 ) 'GeForce RTX 2080'","title":"PyTorch \u3067 GPU \u3092\u78ba\u8a8d"},{"location":"setup/3-docker/#tensorflow_gpu","text":"python3 \u3092\u5b9f\u884c\u3057\u3066\u30a4\u30f3\u30bf\u30e9\u30af\u30c6\u30a3\u30d6\u30e2\u30fc\u30c9\u3067\u78ba\u8a8d\u3059\u308b\u3002 from tensorflow.python.client import device_lib print ( device_lib . list_local_devices ()) \u4e0a\u8a18\u3092\u5b9f\u884c\u3059\u308b\u3068\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u5229\u7528\u3067\u304d\u308b\u30c7\u30d0\u30a4\u30b9\u306e\u4e00\u89a7\u3092\u78ba\u8a8d\u3067\u304d\u308b\u3002 2020-06-06 04:53:00.588924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/device:GPU:0 with 10091 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:17:00.0, compute capability: 7.5) 2020-06-06 04:53:00.590217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/device:GPU:1 with 10202 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)","title":"TensorFlow \u3067 GPU \u3092\u78ba\u8a8d"}]}